




















from deepchem.utils.differentiation_utils.integrate.explicit_rk import mid_point_ivp, fwd_euler_ivp
import matplotlib.pyplot as plt
import torch


# Simple ODE dy/dt = a*y
def ode(t, y, params):
    a = params[0]
    return y * a

t = torch.linspace(0, 20, 5)
y_0 = torch.tensor([1])
a = torch.tensor([1])

sol_fwd_euler = fwd_euler_ivp(ode, y_0, t, [a])
sol_mid_point = mid_point_ivp(ode, y_0, t, [a])

plt.plot(t, sol_fwd_euler, "-b", label="Euler's method")
plt.plot(t, sol_mid_point, "-r", label="Mid-point method")
plt.legend(loc="upper left")
plt.show()





from deepchem.utils.differentiation_utils.integrate.explicit_rk import rk4_ivp
import matplotlib.pyplot as plt
import torch

def sode(variables, t, params):
    y, z = variables

    a = params[0]

    dydt = z
    dzdt = a * y - z

    return torch.tensor([dydt, dzdt])

params = torch.tensor([6])
t = torch.linspace(0, 1, 100)
y0 = torch.tensor([5, -5])
sol = rk4_ivp(sode, y0, t, params)

plt.plot(t, sol[:, 0])
plt.show()





yy = 2 * torch.exp(2 * t) + 3 * torch.exp(-3 * t)

plt.plot(t, yy, "-b", label="Known solution")
plt.plot(t, sol[:, 0], "-r", label="RK4 method")
plt.legend(loc="upper left")
plt.show()





from deepchem.utils.differentiation_utils.integrate.explicit_rk import rk38_ivp
import matplotlib.pyplot as plt
import torch

def lotka_volterra(y, x, params):
    y1, y2 = y
    a, b, c, d = params
    return torch.tensor([(a * y1 - b * y1 * y2), (c * y2 * y1 - d * y2)])

t = torch.linspace(0, 50, 10000)

solver_param = [lotka_volterra,
                torch.tensor([10., 1.]),
                t,
                torch.tensor([1.1, 0.4, 0.1, 0.4])]

sol_rk38 = rk38_ivp(*solver_param)

plt.plot(t, sol_rk38)

plt.show()





import pandas as pd

dataset = pd.read_csv('assets/population_data.csv')
years = torch.tensor(dataset['year'])
fish_pop = torch.tensor(dataset['fish_hundreds'])
bears_pop = torch.tensor(dataset['bears_hundreds'])
pop = torch.tensor(dataset[['fish_hundreds', 'bears_hundreds']].to_numpy())

plt.plot(fish_pop, "-b", label="Fish population")
plt.plot(bears_pop, "-r", label="Bear population")
plt.legend(loc="upper left")
plt.title("Population data")
plt.show()


from deepchem.utils.differentiation_utils.integrate.explicit_rk import rk4_ivp
import torch
import matplotlib.pyplot as plt


def lotka_volterra(y, x, params):
    y1, y2 = y
    a, b, c, d = params

    return torch.tensor([a * y1 - b * y1 * y2, c * y2 * y1 - d * y2])


def loss_function(params, years,fish_pop, bears_pop):

    y0 = torch.tensor([fish_pop[0], bears_pop[0]])

    t = torch.linspace(years[0], years[-1], len(years))

    output = rk4_ivp(lotka_volterra, y0, t, params)

    loss = 0

    for i in range(len(years)):
        data_fish = fish_pop[i]
        model_fish = output[i,0]

        data_bears = bears_pop[i]
        model_bears = output[i,1]

        res = (data_fish - model_fish)**2 + (data_bears - model_bears)**2

        loss += res

    return(loss)

import scipy.optimize

params0 = torch.tensor([1.1, .4, .1, .4])
minimum = scipy.optimize.fmin(loss_function, params0, args=(years,fish_pop, bears_pop))


alpha_fit = minimum[0]
beta_fit = minimum[1]
delta_fit = minimum[2]
gamma_fit = minimum[3]

params = torch.tensor([alpha_fit, beta_fit, delta_fit, gamma_fit])

y0 = torch.tensor([fish_pop[0], bears_pop[0]])

t = torch.linspace(years[0], years[-1], 1000)

output = rk4_ivp(lotka_volterra, y0, t, params)

plt.plot(t, output)
plt.show()


from deepchem.utils.differentiation_utils.integrate.explicit_rk import rk4_ivp
import torch
import matplotlib.pyplot as plt


def lotka_volterra(y, x, params):
    y1, y2 = y
    a, b, c, d = params

    return torch.tensor([a * y1 - b * y1 * y2, c * y2 * y1 - d * y2])


def loss_function(params, years,fish_pop, bears_pop):

    y0 = torch.tensor([fish_pop[0], bears_pop[0]])

    t = torch.linspace(years[0], years[-1], len(years))

    output = rk4_ivp(lotka_volterra, y0, t, params)

    loss = torch.sum((output - pop) ** 2)
    loss.grad = torch.tensor(1.0, dtype=torch.float64)
    
    return loss, loss.grad

from deepchem.utils.differentiation_utils.optimize.minimizer import gd

params0 = torch.tensor([1.1, .4, .1, .4])
minimum = gd(loss_function, params0, params=(years, fish_pop, bears_pop))


alpha_fit = minimum[0]
beta_fit = minimum[1]
delta_fit = minimum[2]
gamma_fit = minimum[3]

params = torch.tensor([alpha_fit, beta_fit, delta_fit, gamma_fit])

y0 = torch.tensor([fish_pop[0], bears_pop[0]])

t = torch.linspace(years[0], years[-1], 1000)

output = rk4_ivp(lotka_volterra, y0, t, params)

plt.plot(t, output)
plt.show()





import torch
import matplotlib.pyplot as plt
from deepchem.utils.differentiation_utils.integrate.explicit_rk import rk4_ivp

def sim(variables, t, params):
    S, I, R = variables

    N = S + I + R

    beta, gamma = params

    dSdt = - beta * I * S / N
    dIdt = beta * I * S / N - gamma * I
    dRdt = gamma * I

    return torch.tensor([dSdt, dIdt, dRdt])

t = torch.linspace(0, 500, 1000)

beta = 0.04
gamma = 0.01

params = torch.tensor([beta, gamma])

y0 = torch.tensor([100, 1, 0])

y = rk4_ivp(sim, y0, t, params)

plt.plot(t, y)
plt.legend(["Susceptible", "Infectious", "Removed"])
plt.show()





import torch
import matplotlib.pyplot as plt
from deepchem.utils.differentiation_utils.integrate.explicit_rk import rk4_ivp

def sim(variables, t, params):
    S, I = variables

    N = S + I

    beta, gamma = params

    dSdt = - beta * I * S / N + gamma * I
    dIdt = beta * I * S / N - gamma * I

    return torch.tensor([dSdt, dIdt])

t = torch.linspace(0, 500, 1000)

beta = 0.04
gamma = 0.01

params = torch.tensor([beta, gamma])

y0 = torch.tensor([100, 1])

y = rk4_ivp(sim, y0, t, params)

plt.plot(t, y)
plt.legend(["Susceptible", "Infectious"])
plt.show()









