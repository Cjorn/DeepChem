{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/daniel.vella/Desktop/dv-box/msc/deepchem\n",
      "/Users/daniel.vella/Desktop/dv-box/msc/deepchem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%cd ../../..\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train low-data siamese models on MUV. Test last fold only.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "# from examples.low_data.datasets import load_muv_convmol\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds for split \n",
    "K = 4\n",
    "# num positive/negative ligands\n",
    "n_pos = 10\n",
    "n_neg = 10\n",
    "# Set batch sizes for network\n",
    "test_batch_size = 128\n",
    "support_batch_size = n_pos + n_neg\n",
    "nb_epochs = 1\n",
    "n_train_trials = 2000\n",
    "n_eval_trials = 20\n",
    "n_steps_per_trial = 1\n",
    "learning_rate = 1e-4\n",
    "log_every_n_samples = 50\n",
    "# Number of features on conv-mols\n",
    "n_feat = 75\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_muv(featurizer='ECFP', split='random')\n",
    "# tasks_copy, datasets_copy, transformers_copy = copy.deepcopy(tasks), copy.deepcopy(datasets), copy.deepcopy(transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DiskDataset X.shape: (74469, 1024), y.shape: (74469, 17), w.shape: (74469, 17), task_names: ['MUV-466' 'MUV-548' 'MUV-600' ... 'MUV-852' 'MUV-858' 'MUV-859']>\n"
     ]
    }
   ],
   "source": [
    "# X contains 74469 samples with fingerprint of length 1024\n",
    "# y represents 17 tasks of the MUV tasks\n",
    "# w represents weights\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1000, activation='tanh'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model = dc.models.KerasModel(keras_model,\n",
    "                             loss=dc.models.losses.L2Loss())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008366763591766358"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,\n",
    "         nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRC AUC recommended for MUV\n",
    "metric = dc.metrics.Metric(dc.metrics.prc_auc_score, mode=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of input doesn't match expected n_tasks=17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-3a7dfddd9ed8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/dv-box/msc/deepchem/deepchem/models/models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, metrics, transformers, per_task_metrics, use_sample_weights, n_classes)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mper_task_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_task_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0muse_sample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_sample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         n_classes=n_classes)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_task_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/dv-box/msc/deepchem/deepchem/utils/evaluate.py\u001b[0m in \u001b[0;36mcompute_model_performance\u001b[0;34m(self, metrics, csv_out, stats_out, per_task_metrics, use_sample_weights, n_classes)\u001b[0m\n\u001b[1;32m    314\u001b[0m           \u001b[0mn_tasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_tasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m           \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m           use_sample_weights=use_sample_weights)\n\u001b[0m\u001b[1;32m    317\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mper_task_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mmultitask_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputed_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/dv-box/msc/deepchem/deepchem/metrics/metric.py\u001b[0m in \u001b[0;36mcompute_metric\u001b[0;34m(self, y_true, y_pred, w, n_tasks, n_classes, filter_nans, per_task_metrics, use_sample_weights, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m         y_true, mode=self.mode, n_tasks=n_tasks, n_classes=n_classes)\n\u001b[1;32m    644\u001b[0m     y_pred = normalize_prediction_shape(\n\u001b[0;32m--> 645\u001b[0;31m         y_pred, mode=self.mode, n_tasks=n_tasks, n_classes=n_classes)\n\u001b[0m\u001b[1;32m    646\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m       y_true = handle_classification_mode(\n",
      "\u001b[0;32m~/Desktop/dv-box/msc/deepchem/deepchem/metrics/metric.py\u001b[0m in \u001b[0;36mnormalize_prediction_shape\u001b[0;34m(y, mode, n_tasks, n_classes)\u001b[0m\n\u001b[1;32m    245\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_tasks\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     raise ValueError(\n\u001b[0;32m--> 247\u001b[0;31m         \"Shape of input doesn't match expected n_tasks=%d\" % n_tasks)\n\u001b[0m\u001b[1;32m    248\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of input doesn't match expected n_tasks=17"
     ]
    }
   ],
   "source": [
    "print(\"Training Score: \", model.evaluate(train_dataset, metric, transformers, n_classes=17, use_sample_weights=True))\n",
    "print(\"Test Score: \", model.evaluate(test_dataset, metric, transformers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_splitter = dc.splits.TaskSplitter()\n",
    "# fold_datasets = task_splitter.k_fold_split(dataset, K)\n",
    "\n",
    "# train_folds = fold_datasets[:-1]\n",
    "# train_dataset = dc.splits.merge_fold_datasets(train_folds)\n",
    "# test_dataset = fold_datasets[-1]\n",
    "\n",
    "# Train support model on train\n",
    "support_model = dc.nn.SequentialSupportGraph(n_feat)\n",
    "\n",
    "# Add layers\n",
    "support_model.add(dc.nn.GraphConv(64, n_feat, activation='relu'))\n",
    "support_model.add(dc.nn.GraphPool())\n",
    "support_model.add(dc.nn.GraphConv(128, 64, activation='relu'))\n",
    "support_model.add(dc.nn.GraphPool())\n",
    "support_model.add(dc.nn.GraphConv(64, 128, activation='relu'))\n",
    "support_model.add(dc.nn.GraphPool())\n",
    "support_model.add(dc.nn.Dense(128, 64, activation='tanh'))\n",
    "\n",
    "support_model.add_test(dc.nn.GraphGather(test_batch_size, activation='tanh'))\n",
    "support_model.add_support(\n",
    "    dc.nn.GraphGather(support_batch_size, activation='tanh'))\n",
    "\n",
    "model = dc.models.SupportGraphClassifier(\n",
    "    support_model,\n",
    "    test_batch_size=test_batch_size,\n",
    "    support_batch_size=support_batch_size,\n",
    "    learning_rate=learning_rate)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    nb_epochs=nb_epochs,\n",
    "    n_episodes_per_epoch=n_train_trials,\n",
    "    n_pos=n_pos,\n",
    "    n_neg=n_neg,\n",
    "    log_every_n_samples=log_every_n_samples)\n",
    "mean_scores, std_scores = model.evaluate(\n",
    "    test_dataset, metric, n_pos, n_neg, n_trials=n_eval_trials)\n",
    "\n",
    "print(\"Mean Scores on evaluation dataset\")\n",
    "print(mean_scores)\n",
    "print(\"Standard Deviations on evaluation dataset\")\n",
    "print(std_scores)\n",
    "print(\"Median of Mean Scores\")\n",
    "print(np.median(np.array(mean_scores.values())))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
