{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/daniel.vella/Desktop/dv-box/msc/deepchem\n",
      "/Users/daniel.vella/Desktop/dv-box/msc/deepchem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%cd ../../..\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train low-data siamese models on MUV. Test last fold only.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_sider(featurizer='ECFP', splitter='random')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_datasets(dataset):\n",
    "    datasets = []\n",
    "    num_tasks = len(dataset.tasks)\n",
    "    \n",
    "    for n in range(num_tasks):        \n",
    "        X = pd.DataFrame(dataset.X, columns = ['X' + str(i + 1) for i in range(dataset.X.shape[1])])\n",
    "        y = pd.Series(dataset.y[:, n], name='y')\n",
    "        w = pd.Series(dataset.w[:, n], name='w')\n",
    "        ids = pd.Series(dataset.ids, name='ids')\n",
    "    \n",
    "        df = X.assign(y=y.values, w=w.values, ids=ids.values, task=dataset.tasks[n])\n",
    "        ds = dc.data.DiskDataset.from_dataframe(df)\n",
    "        datasets.append(ds)\n",
    "    return datasets\n",
    "\n",
    "train_datasets = get_task_datasets(train_dataset)\n",
    "test_datasets = get_task_datasets(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010704271793365479"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1024, 1000),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(1000, 1)\n",
    ")\n",
    "\n",
    "model = dc.models.TorchModel(pytorch_model, dc.models.losses.L2Loss())\n",
    "\n",
    "# metric = dc.metrics.Metric(dc.metrics.roc_auc_score, mode=\"classification\")\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "\n",
    "model.fit(train_datasets[0], nb_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'pearson_r2_score': 0.9935988886688238}\n",
      "test set score: {'pearson_r2_score': 0.1778891014960177}\n"
     ]
    }
   ],
   "source": [
    "print('training set score:', model.evaluate(train_datasets[0], [metric]))\n",
    "print('test set score:', model.evaluate(test_datasets[0], [metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_splitter = dc.splits.TaskSplitter()\n",
    "# fold_datasets = task_splitter.k_fold_split(dataset, K)\n",
    "\n",
    "# train_folds = fold_datasets[:-1]\n",
    "# train_dataset = dc.splits.merge_fold_datasets(train_folds)\n",
    "# test_dataset = fold_datasets[-1]\n",
    "\n",
    "# Train support model on train\n",
    "# support_model = dc.nn.SequentialSupportGraph(n_feat)\n",
    "\n",
    "# # Add layers\n",
    "# support_model.add(dc.nn.GraphConv(64, n_feat, activation='relu'))\n",
    "# support_model.add(dc.nn.GraphPool())\n",
    "# support_model.add(dc.nn.GraphConv(128, 64, activation='relu'))\n",
    "# support_model.add(dc.nn.GraphPool())\n",
    "# support_model.add(dc.nn.GraphConv(64, 128, activation='relu'))\n",
    "# support_model.add(dc.nn.GraphPool())\n",
    "# support_model.add(dc.nn.Dense(128, 64, activation='tanh'))\n",
    "\n",
    "# support_model.add_test(dc.nn.GraphGather(test_batch_size, activation='tanh'))\n",
    "# support_model.add_support(\n",
    "#     dc.nn.GraphGather(support_batch_size, activation='tanh'))\n",
    "\n",
    "# model = dc.models.SupportGraphClassifier(\n",
    "#     support_model,\n",
    "#     test_batch_size=test_batch_size,\n",
    "#     support_batch_size=support_batch_size,\n",
    "#     learning_rate=learning_rate)\n",
    "\n",
    "# model.fit(\n",
    "#     train_dataset,\n",
    "#     nb_epochs=nb_epochs,\n",
    "#     n_episodes_per_epoch=n_train_trials,\n",
    "#     n_pos=n_pos,\n",
    "#     n_neg=n_neg,\n",
    "#     log_every_n_samples=log_every_n_samples)\n",
    "# mean_scores, std_scores = model.evaluate(\n",
    "#     test_dataset, metric, n_pos, n_neg, n_trials=n_eval_trials)\n",
    "\n",
    "# print(\"Mean Scores on evaluation dataset\")\n",
    "# print(mean_scores)\n",
    "# print(\"Standard Deviations on evaluation dataset\")\n",
    "# print(std_scores)\n",
    "# print(\"Median of Mean Scores\")\n",
    "# print(np.median(np.array(mean_scores.values())))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
