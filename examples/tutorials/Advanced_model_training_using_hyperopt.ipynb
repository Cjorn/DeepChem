{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjoSNeI9RUKi"
      },
      "source": [
        "#**Advanced model training using hyperopt**\n",
        "\n",
        "In the Advanced Model Training tutorial we have already taken a look into hyperparameter optimasation using GridHyperparamOpt in the deepchem pacakge. In this tutorial, we will take a look into another hyperparameter tuning library called hyperopt.\n",
        "\n",
        "## Colab\n",
        "\n",
        "This tutorial and the rest in this sequence can be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/Advanced_model_training_using_hyperopt.ipynb)\n",
        "\n",
        "## Setup\n",
        "\n",
        "To run DeepChem and Hyperopt within Colab, you'll need to run the following installation commands. You can of course run this tutorial locally if you prefer. In that case, don't run these cells since they will download and install DeepChem and Hyperopt in your local machine again.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70xCmMITvql",
        "outputId": "2fe5efeb-a525-482b-d950-5bc4929e7fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepchem\n",
            "  Downloading deepchem-2.7.1-py3-none-any.whl (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.9\n",
            "  Downloading scipy-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from deepchem) (1.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from deepchem) (1.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from deepchem) (1.3.5)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from deepchem) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->deepchem) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from rdkit->deepchem) (8.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->deepchem) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: scipy, rdkit, deepchem\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "Successfully installed deepchem-2.7.1 rdkit-2022.9.5 scipy-1.8.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.9/dist-packages (0.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from hyperopt) (1.22.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from hyperopt) (3.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.9/dist-packages (from hyperopt) (4.3.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from hyperopt) (1.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from hyperopt) (4.65.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from pymongo->hyperopt) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install deepchem\n",
        "!pip install hyperopt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRpJ-BvHRTIE"
      },
      "source": [
        "## Hyperparameter Optimization via hyperopt\n",
        "\n",
        "Let's start by loading the HIV dataset.  It classifies over 40,000 molecules based on whether they inhibit HIV replication.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0aDZ3aY6dkk",
        "outputId": "049bfb99-0604-4c11-b3eb-da28b2bfae37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.9/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n",
            "[07:22:09] WARNING: not removing hydrogen atom without neighbors\n",
            "[07:22:09] WARNING: not removing hydrogen atom without neighbors\n",
            "[07:22:40] WARNING: not removing hydrogen atom without neighbors\n",
            "[07:22:40] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        }
      ],
      "source": [
        "import deepchem as dc\n",
        "tasks, datasets, transformers = dc.molnet.load_hiv(featurizer='ECFP', splitter='scaffold')\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnr75060q1j9"
      },
      "source": [
        "Now, lets import the hyperopt library, which we will be using to fund the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xM7G0LS1q1V_"
      },
      "outputs": [],
      "source": [
        "from hyperopt import hp, fmin, tpe, Trials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztSRJo3krDUm"
      },
      "source": [
        "Then we have to declare a dictionary with all the hyperparameters and their range that you will be tuning them in. This dictionary will serve as the search space for the hyperopt. \n",
        "Some basic ways of declaring the ranges in the dictionary are:\n",
        "\n",
        "\n",
        "\n",
        "*   hp.choice('label',[*choices*]) : this is used to specify a list of choices\n",
        "*   hp.uniform('label' ,low=*low_value* ,high=*high_value*) :  this is used to specify a uniform distibution between the low and high values. The values between them can be any real number, not necessaarily an integer.\n",
        "\n",
        "Here, we are going to use a multitaskclassifier to classify the HIV dataset and hence the appropriate search space is as follows.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vGeRn7oWUWo_"
      },
      "outputs": [],
      "source": [
        "search_space = {\n",
        "    'layer_sizes': hp.choice('layer_sizes',[[500], [1000], [2000], [1000,1000]]),\n",
        "    'dropouts': hp.uniform('dropout', low=0.2, high=0.5),\n",
        "    'learning_rate': hp.uniform('learning_rate', high=0.001, low=0.0001)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJzohvgFs70N"
      },
      "source": [
        "We should then declare a function to be minimized by the hyperopt. So, here we should use the function to minimize our multitaskclassifier model. Additionally, we are using a validation callback to validate the classifier for every 1000 steps, then we are passing the best score as the return. The metric used here is 'roc_auc_score', which needs to be maximized. To maximize a non-negative value is equivalent to minimize its opposite number, hence we are returning the negative of the validation score.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iEFj6HuetG1P"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "#tempfile is used to save the best checkpoint later in the program.\n",
        "\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
        "\n",
        "def fm(args):\n",
        "  save_dir = tempfile.mkdtemp()\n",
        "  model = dc.models.MultitaskClassifier(n_tasks=len(tasks),\n",
        "                      n_features=1024,\n",
        "                      layer_sizes=args['layer_sizes'],\n",
        "                      dropouts=args['dropouts'],\n",
        "                      learning_rate=args['learning_rate'])\n",
        "  #validation callback that saves the best checkpoint, i.e the one with the maximum score.\n",
        "  validation=dc.models.ValidationCallback(valid_dataset, 1000, [metric], save_dir=save_dir, transformers=transformers, save_on_minimum=False)\n",
        "  \n",
        "  model.fit(train_dataset, nb_epoch=25, callbacks=validation)\n",
        "\n",
        "  #restoring the best checkpoint and passing the negative of its validation score to be minimized.\n",
        "  model.restore(model_dir=save_dir)\n",
        "  valid_score = model.evaluate(valid_dataset, [metric], transformers)\n",
        "\n",
        "  return -1 * valid_score['roc_auc_score']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McC5wuJax6IR"
      },
      "source": [
        "Here, we are calling the fmin function of the hyperopt, where we pass on the function to be minimized, the algorithm to be followed, max number of evals and a trials object. The Trials object is used to keep All hyperparameters, loss, and other information, this means you can access them after running optimization. Also, trials can help you to save important information and later load and then resume the optimization process.\n",
        "\n",
        "Moreover, for the algorithm there are three choice which can be used without any additional configuration. they are :-  \n",
        "\n",
        "\n",
        "*   Random Search - rand.suggest\n",
        "*   TPE (Tree Parzen Estimators) - tpe.suggest\n",
        "*   Adaptive TPE - atpe.suggest\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1i3yc7ECWVq",
        "outputId": "3087b334-635a-4110-f4d0-f286181573a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s, best loss: ?]Step 1000 validation: roc_auc_score=0.738666\n",
            "Step 2000 validation: roc_auc_score=0.759833\n",
            "Step 3000 validation: roc_auc_score=0.750727\n",
            "Step 4000 validation: roc_auc_score=0.767338\n",
            "Step 5000 validation: roc_auc_score=0.750678\n",
            "Step 6000 validation: roc_auc_score=0.751681\n",
            "Step 7000 validation: roc_auc_score=0.727666\n",
            "Step 8000 validation: roc_auc_score=0.73623\n",
            "  7%|▋         | 1/15 [06:15<1:27:38, 375.61s/it, best loss: -0.7673381466784244]Step 1000 validation: roc_auc_score=0.731238\n",
            "Step 2000 validation: roc_auc_score=0.759585\n",
            "Step 3000 validation: roc_auc_score=0.756392\n",
            "Step 4000 validation: roc_auc_score=0.760106\n",
            "Step 5000 validation: roc_auc_score=0.764393\n",
            "Step 6000 validation: roc_auc_score=0.762134\n",
            "Step 7000 validation: roc_auc_score=0.765014\n",
            "Step 8000 validation: roc_auc_score=0.763192\n",
            " 13%|█▎        | 2/15 [11:49<1:16:03, 351.04s/it, best loss: -0.7673381466784244]Step 1000 validation: roc_auc_score=0.736817\n",
            "Step 2000 validation: roc_auc_score=0.769503\n",
            "Step 3000 validation: roc_auc_score=0.764653\n",
            "Step 4000 validation: roc_auc_score=0.761756\n",
            "Step 5000 validation: roc_auc_score=0.781337\n",
            "Step 6000 validation: roc_auc_score=0.774068\n",
            "Step 7000 validation: roc_auc_score=0.771037\n",
            "Step 8000 validation: roc_auc_score=0.769221\n",
            " 20%|██        | 3/15 [13:26<47:03, 235.27s/it, best loss: -0.7813372648442094]  Step 1000 validation: roc_auc_score=0.751177\n",
            "Step 2000 validation: roc_auc_score=0.774117\n",
            "Step 3000 validation: roc_auc_score=0.78213\n",
            "Step 4000 validation: roc_auc_score=0.779667\n",
            "Step 5000 validation: roc_auc_score=0.768416\n",
            "Step 6000 validation: roc_auc_score=0.778542\n",
            "Step 7000 validation: roc_auc_score=0.775269\n",
            "Step 8000 validation: roc_auc_score=0.764344\n",
            " 27%|██▋       | 4/15 [18:51<49:34, 270.43s/it, best loss: -0.7821303032529884]Step 1000 validation: roc_auc_score=0.70685\n",
            "Step 2000 validation: roc_auc_score=0.739769\n",
            "Step 3000 validation: roc_auc_score=0.764858\n",
            "Step 4000 validation: roc_auc_score=0.764396\n",
            "Step 5000 validation: roc_auc_score=0.765574\n",
            "Step 6000 validation: roc_auc_score=0.768679\n",
            "Step 7000 validation: roc_auc_score=0.765636\n",
            "Step 8000 validation: roc_auc_score=0.770363\n",
            " 33%|███▎      | 5/15 [20:26<34:32, 207.22s/it, best loss: -0.7821303032529884]Step 1000 validation: roc_auc_score=0.725962\n",
            "Step 2000 validation: roc_auc_score=0.766398\n",
            "Step 3000 validation: roc_auc_score=0.768796\n",
            "Step 4000 validation: roc_auc_score=0.772305\n",
            "Step 5000 validation: roc_auc_score=0.777387\n",
            "Step 6000 validation: roc_auc_score=0.772045\n",
            "Step 7000 validation: roc_auc_score=0.776729\n",
            "Step 8000 validation: roc_auc_score=0.780124\n",
            " 40%|████      | 6/15 [22:04<25:29, 169.97s/it, best loss: -0.7821303032529884]Step 1000 validation: roc_auc_score=0.769886\n",
            "Step 2000 validation: roc_auc_score=0.779473\n",
            "Step 3000 validation: roc_auc_score=0.773673\n",
            "Step 4000 validation: roc_auc_score=0.779992\n",
            "Step 5000 validation: roc_auc_score=0.783521\n",
            "Step 6000 validation: roc_auc_score=0.776204\n",
            "Step 7000 validation: roc_auc_score=0.770194\n",
            "Step 8000 validation: roc_auc_score=0.771404\n",
            " 47%|████▋     | 7/15 [23:38<19:23, 145.42s/it, best loss: -0.7835211823927102]Step 1000 validation: roc_auc_score=0.721529\n",
            "Step 2000 validation: roc_auc_score=0.758777\n",
            "Step 3000 validation: roc_auc_score=0.766383\n",
            "Step 4000 validation: roc_auc_score=0.752154\n",
            "Step 5000 validation: roc_auc_score=0.769644\n",
            "Step 6000 validation: roc_auc_score=0.767001\n",
            "Step 7000 validation: roc_auc_score=0.77382\n",
            "Step 8000 validation: roc_auc_score=0.772864\n",
            " 53%|█████▎    | 8/15 [25:15<15:08, 129.82s/it, best loss: -0.7835211823927102]Step 1000 validation: roc_auc_score=0.727135\n",
            "Step 2000 validation: roc_auc_score=0.738976\n",
            "Step 3000 validation: roc_auc_score=0.752221\n",
            "Step 4000 validation: roc_auc_score=0.776815\n",
            "Step 5000 validation: roc_auc_score=0.76671\n",
            "Step 6000 validation: roc_auc_score=0.764116\n",
            "Step 7000 validation: roc_auc_score=0.768058\n",
            "Step 8000 validation: roc_auc_score=0.764164\n",
            " 60%|██████    | 9/15 [28:11<14:25, 144.18s/it, best loss: -0.7835211823927102]Step 1000 validation: roc_auc_score=0.738045\n",
            "Step 2000 validation: roc_auc_score=0.757685\n",
            "Step 3000 validation: roc_auc_score=0.779097\n",
            "Step 4000 validation: roc_auc_score=0.758473\n",
            "Step 5000 validation: roc_auc_score=0.764711\n",
            "Step 6000 validation: roc_auc_score=0.767687\n",
            "Step 7000 validation: roc_auc_score=0.77228\n",
            "Step 8000 validation: roc_auc_score=0.771297\n",
            " 67%|██████▋   | 10/15 [33:29<16:29, 197.86s/it, best loss: -0.7835211823927102]Step 1000 validation: roc_auc_score=0.753027\n",
            "Step 2000 validation: roc_auc_score=0.777176\n",
            "Step 3000 validation: roc_auc_score=0.777158\n",
            "Step 4000 validation: roc_auc_score=0.77706\n",
            "Step 5000 validation: roc_auc_score=0.766947\n",
            "Step 6000 validation: roc_auc_score=0.772013\n",
            "Step 7000 validation: roc_auc_score=0.76816\n",
            "Step 8000 validation: roc_auc_score=0.770625\n",
            " 73%|███████▎  | 11/15 [35:07<11:10, 167.52s/it, best loss: -0.7835211823927102]Step 1000 validation: roc_auc_score=0.738137\n",
            "Step 2000 validation: roc_auc_score=0.761588\n",
            "Step 3000 validation: roc_auc_score=0.765862\n",
            "Step 4000 validation: roc_auc_score=0.758679\n",
            "Step 5000 validation: roc_auc_score=0.774307\n",
            "Step 6000 validation: roc_auc_score=0.774054\n",
            "Step 7000 validation: roc_auc_score=0.786233\n",
            "Step 8000 validation: roc_auc_score=0.774338\n",
            " 80%|████████  | 12/15 [38:02<08:28, 169.55s/it, best loss: -0.7862332818930042]Step 1000 validation: roc_auc_score=0.729882\n",
            "Step 2000 validation: roc_auc_score=0.75197\n",
            "Step 3000 validation: roc_auc_score=0.779947\n",
            "Step 4000 validation: roc_auc_score=0.781062\n",
            "Step 5000 validation: roc_auc_score=0.775673\n",
            "Step 6000 validation: roc_auc_score=0.77509\n",
            "Step 7000 validation: roc_auc_score=0.778806\n",
            "Step 8000 validation: roc_auc_score=0.77656\n",
            " 87%|████████▋ | 13/15 [39:41<04:56, 148.35s/it, best loss: -0.7862332818930042]Step 1000 validation: roc_auc_score=0.745479\n",
            "Step 2000 validation: roc_auc_score=0.773517\n",
            "Step 3000 validation: roc_auc_score=0.777003\n",
            "Step 4000 validation: roc_auc_score=0.759873\n",
            "Step 5000 validation: roc_auc_score=0.763401\n",
            "Step 6000 validation: roc_auc_score=0.76768\n",
            "Step 7000 validation: roc_auc_score=0.768718\n",
            "Step 8000 validation: roc_auc_score=0.758427\n",
            " 93%|█████████▎| 14/15 [45:03<03:20, 200.76s/it, best loss: -0.7862332818930042]Step 1000 validation: roc_auc_score=0.71452\n",
            "Step 2000 validation: roc_auc_score=0.742031\n",
            "Step 3000 validation: roc_auc_score=0.722824\n",
            "Step 4000 validation: roc_auc_score=0.767882\n",
            "Step 5000 validation: roc_auc_score=0.723091\n",
            "Step 6000 validation: roc_auc_score=0.741095\n",
            "Step 7000 validation: roc_auc_score=0.719949\n",
            "Step 8000 validation: roc_auc_score=0.752116\n",
            "100%|██████████| 15/15 [50:56<00:00, 203.76s/it, best loss: -0.7862332818930042]\n"
          ]
        }
      ],
      "source": [
        "trials=Trials()\n",
        "best = fmin(fm,\n",
        "    \t\tspace=search_space,\n",
        "    \t\talgo=tpe.suggest,\n",
        "    \t\tmax_evals=15,\n",
        "    \t\ttrials=trials)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I9CzaylyjUw"
      },
      "source": [
        "The code below is used to print the best hyperparameters found by the hyperopt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPeJaH89GD67",
        "outputId": "b267691c-d5c6-4d01-cef1-49946dc27013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: {'dropout': 0.24165404739692975, 'layer_sizes': 1, 'learning_rate': 0.00023508803192311167}\n"
          ]
        }
      ],
      "source": [
        "print(\"Best: {}\".format(best))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD1ET6q6_naf"
      },
      "source": [
        "The hyperparameter found here may not be necessarily the best one, but gives a general idea on which parameters are effective. To get mroe accurate results, one has to increase the number of validation epochs and the epochs the model fit. But doing so may increase the time in finding the best hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng2npVmkyvpQ"
      },
      "source": [
        "# Congratulations! Time to join the Community!\n",
        "\n",
        "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
        "\n",
        "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
        "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
        "\n",
        "## Join the DeepChem Gitter\n",
        "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
