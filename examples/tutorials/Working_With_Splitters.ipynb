{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTuYGOlnh117"
   },
   "source": [
    "#  Working With Splitters\n",
    "\n",
    "When using machine learning, you typically divide your data into training, validation, and test sets.  The MoleculeNet loaders do this automatically.  But how should you divide up the data?  This question seems simple at first, but it turns out to be quite complicated.  There are many ways of splitting up data, and which one you choose can have a big impact on the reliability of your results.  This tutorial introduces some of the splitting methods provided by DeepChem.\n",
    "\n",
    "## Colab\n",
    "\n",
    "This tutorial and the rest in this sequence can be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/Working_With_Splitters.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "D43MbibL_EK0",
    "outputId": "e7b205ae-9962-4089-d49a-6d0ebe4c8430"
   },
   "outputs": [],
   "source": [
    "!pip install --pre deepchem\n",
    "import deepchem\n",
    "deepchem.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omxBgQVDh12B"
   },
   "source": [
    "## Splitters\n",
    "\n",
    "In DeepChem, a method of splitting samples into multiple datasets is defined by a `Splitter` object.  Choosing an appropriate method for your data is very important.  Otherwise, your trained model may seem to work much better than it really does.\n",
    "\n",
    "Consider a typical drug development pipeline.  You might begin by screening many thousands of molecules to see if they bind to your target of interest.  Once you find one that seems to work, you try to optimize it by testing thousands of minor variations on it, looking for one that binds more strongly.  Then perhaps you test it in animals and find it has unacceptable toxicity, so you try more variations to fix the problems.\n",
    "\n",
    "This has an important consequence for chemical datasets: they often include lots of molecules that are very similar to each other.  If you split the data into training and test sets in a naive way, the training set will include many molecules that are very similar to the ones in the test set, even if they are not exactly identical.  As a result, the model may do very well on the test set, but then fail badly when you try to use it on other data that is less similar to the training data.\n",
    "\n",
    "Let's take a look at a few of the splitters found in DeepChem.\n",
    "\n",
    "### • General Splitters\n",
    "      ○ RandomSplitter\n",
    "      ○ RandomGroupSplitter\n",
    "      ○ RandomStratifiedSplitter\n",
    "      ○ SingletaskStratifiedSplitter\n",
    "      ○ IndexSplitter\n",
    "      ○ SpecifiedSplitter\n",
    "      ○ TaskSplitter\n",
    "\n",
    "### • Molecular Splitters\n",
    "      ○ ScaffoldSplitter\n",
    "      ○ MolecularWeightSplitter\n",
    "      ○ MaxMinSplitter\n",
    "      ○ ButinaSplitter\n",
    "      ○ FingerprintSplitter\n",
    "\n",
    "\n",
    " Let's take a look how different splitters work.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### RandomSplitter\n",
    "\n",
    "This is one of the simplest splitters.  It just selects samples for the training, validation, and test sets in a completely random way.\n",
    "\n",
    "Didn't we just say that's a bad idea?  Well, it depends on your data.  If every sample is truly independent of every other, then this is just as good a way as any to split the data.  There is no universally best choice of splitter.  It all depends on your particular dataset, and for some datasets this is a fine choice.\n",
    "\n",
    "### RandomStratifiedSplitter\n",
    "\n",
    "Some datasets are very unbalanced: only a tiny fraction of all samples are positive.  In that case, random splitting may sometimes lead to the validation or test set having few or even no positive samples for some tasks.  That makes it unable to evaluate performance.\n",
    "\n",
    "`RandomStratifiedSplitter` addresses this by dividing up the positive and negative samples evenly.  If you ask for a 80/10/10 split, the validation and test sets will contain not just 10% of samples, but also 10% of the positive samples for each task.\n",
    "\n",
    "### ScaffoldSplitter\n",
    "\n",
    "This splitter tries to address the problem discussed above where many molecules are very similar to each other.  It identifies the scaffold that forms the core of each molecule, and ensures that all molecules with the same scaffold are put into the same dataset.  This is still not a perfect solution, since two molecules may have different scaffolds but be very similar in other ways, but it usually is a large improvement over random splitting.\n",
    "\n",
    "### ButinaSplitter\n",
    "\n",
    "This is another splitter that tries to address the problem of similar molecules.  It clusters them based on their molecular fingerprints, so that ones with similar fingerprints will tend to be in the same dataset.  The time required by this splitting algorithm scales as the square of the number of molecules, so it is mainly useful for small to medium sized datasets.\n",
    "\n",
    "### SpecifiedSplitter\n",
    "\n",
    "This splitter leaves everything up to the user.  You tell it exactly which samples to put in each dataset.  This is useful when you know in advance that a particular splitting is appropriate for your data.\n",
    "\n",
    "An example is temporal splitting.  Consider a research project where you are continually generating and testing new molecules.  As you gain more data, you periodically retrain your model on the steadily growing dataset, then use it to predict results for other not yet tested molecules.  A good way of validating whether this works is to pick a particular cutoff date, train the model on all data you had at that time, and see how well it predicts other data that was generated later.\n",
    "\n",
    "### TaskSplitter\n",
    "\n",
    "Provides a simple interface for splitting datasets task-wise.\n",
    "\n",
    "For some learning problems, the training and test datasets should have different tasks entirely. This is a different paradigm from the usual Splitter, which ensures that split datasets have different data points, not different tasks. This method improves multi-task learning and problem decomposition situations by enhancing their efficiency and performance.\n",
    "\n",
    "### SingletaskStratifiedSplitter\n",
    "\n",
    "Another way of splitting data, particularly for classification tasks with imbalanced class distributions is the single-task stratified splitter. The single-task stratified splitter maintains the class distribution in the original dataset across training, validation and test sets. This is crucial when working with imbalanced datasets where some classes may be under-represented.\n",
    "\n",
    "### FingerprintSplitter\n",
    "\n",
    "Class for doing data splits based on the Tanimoto similarity(Tanimoto similarity measures overlap between two sets succinctly) between ECFP4 fingerprints(ECFP4 fingerprints encode unique parts of molecules for efficient comparison).\n",
    "\n",
    "This class tries to split the data such that the molecules in each dataset are as different as possible from the ones in the other datasets. This makes it a very stringent test of models. Predicting the test and validation sets may require extrapolating far outside the training data.It splits molecular datasets using Tanimoto similarity scores calculated from ECFP4 fingerprints. ECFP4, based on Morgan fingerprints, encodes molecular substructures.\n",
    "\n",
    "### MolecularWeightSplitter\n",
    "\n",
    "Another splitter performs data splits based on molecular weight\n",
    "\n",
    "\n",
    "## Effect of Using Different Splitters\n",
    "\n",
    "Let's look at an example.  We will load the Tox21 toxicity dataset using random,fingerprint, scaffold, and Butina splitting.  For each one we train a model and evaluate it on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sp5Hbb4nh12C"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No Metadata Found On Disk",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m metric \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMetric(dc\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mroc_auc_score)\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m splitter \u001b[39min\u001b[39;00m splitters:\n\u001b[0;32m----> 6\u001b[0m     tasks, datasets, transformers \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39;49mmolnet\u001b[39m.\u001b[39;49mload_tox21(featurizer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mECFP\u001b[39;49m\u001b[39m'\u001b[39;49m, splitter\u001b[39m=\u001b[39;49msplitter)\n\u001b[1;32m      7\u001b[0m     train_dataset, valid_dataset, test_dataset \u001b[39m=\u001b[39m datasets\n\u001b[1;32m      8\u001b[0m     model \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mMultitaskClassifier(n_tasks\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(tasks), n_features\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m, layer_sizes\u001b[39m=\u001b[39m[\u001b[39m1000\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/deepchem/lib/python3.8/site-packages/deepchem/molnet/load_function/tox21_datasets.py:83\u001b[0m, in \u001b[0;36mload_tox21\u001b[0;34m(featurizer, splitter, transformers, reload, data_dir, save_dir, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load Tox21 dataset\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[39mThe \"Toxicology in the 21st Century\" (Tox21) initiative created a public\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39m.. [1] Tox21 Challenge. https://tripod.nih.gov/tox21/challenge/\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m loader \u001b[39m=\u001b[39m _Tox21Loader(featurizer, splitter, transformers, TOX21_TASKS,\n\u001b[1;32m     82\u001b[0m                       data_dir, save_dir, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m loader\u001b[39m.\u001b[39;49mload_dataset(\u001b[39m'\u001b[39;49m\u001b[39mtox21\u001b[39;49m\u001b[39m'\u001b[39;49m, reload)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepchem/lib/python3.8/site-packages/deepchem/molnet/load_function/molnet_loader.py:169\u001b[0m, in \u001b[0;36m_MolnetLoader.load_dataset\u001b[0;34m(self, name, reload)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtasks, (DiskDataset(save_folder),), transformers\n\u001b[1;32m    168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m   loaded, all_dataset, transformers \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mdata_utils\u001b[39m.\u001b[39;49mload_dataset_from_disk(\n\u001b[1;32m    170\u001b[0m       save_folder)\n\u001b[1;32m    171\u001b[0m   \u001b[39mif\u001b[39;00m all_dataset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtasks, all_dataset, transformers\n",
      "File \u001b[0;32m~/anaconda3/envs/deepchem/lib/python3.8/site-packages/deepchem/utils/data_utils.py:577\u001b[0m, in \u001b[0;36mload_dataset_from_disk\u001b[0;34m(save_dir)\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mlist\u001b[39m()\n\u001b[1;32m    576\u001b[0m loaded \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m train \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDiskDataset(train_dir)\n\u001b[1;32m    578\u001b[0m valid \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDiskDataset(valid_dir)\n\u001b[1;32m    579\u001b[0m test \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDiskDataset(test_dir)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepchem/lib/python3.8/site-packages/deepchem/data/datasets.py:1215\u001b[0m, in \u001b[0;36mDiskDataset.__init__\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir \u001b[39m=\u001b[39m data_dir\n\u001b[1;32m   1214\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mLoading dataset from disk.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1215\u001b[0m tasks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_metadata()\n\u001b[1;32m   1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtasks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(tasks)\n\u001b[1;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df\u001b[39m.\u001b[39mcolumns) \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   1218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df\u001b[39m.\u001b[39mcolumns) \u001b[39m==\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mids\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/deepchem/lib/python3.8/site-packages/deepchem/data/datasets.py:1302\u001b[0m, in \u001b[0;36mDiskDataset.load_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1300\u001b[0m   DiskDataset\u001b[39m.\u001b[39m_save_metadata(metadata_df, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir, tasks)\n\u001b[1;32m   1301\u001b[0m   \u001b[39mreturn\u001b[39;00m tasks, metadata_df\n\u001b[0;32m-> 1302\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo Metadata Found On Disk\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No Metadata Found On Disk"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "splitters = ['random', 'scaffold', 'butina','fingerprint']\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "for splitter in splitters:\n",
    "    tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='ECFP', splitter=splitter)\n",
    "    train_dataset, valid_dataset, test_dataset = datasets\n",
    "    model = dc.models.MultitaskClassifier(n_tasks=len(tasks), n_features=1024, layer_sizes=[1000])\n",
    "    model.fit(train_dataset, nb_epoch=10)\n",
    "    print('splitter:', splitter)\n",
    "    print('training set score:', model.evaluate(train_dataset, [metric], transformers))\n",
    "    print('test set score:', model.evaluate(test_dataset, [metric], transformers))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of them produce very similar performance on the training set, but the random splitter has much higher performance on the test set.  Scaffold splitting has a lower test set score, and Butina splitting is even lower.  Does that mean random splitting is better?  No!  It means random splitting doesn't give you an accurate measure of how well your model works.  Because the test set contains lots of molecules that are very similar to ones in the training set, it isn't truly independent.  It makes the model appear to work better than it really does.  Scaffold splitting and Butina splitting give a better indication of what you can expect on independent data in the future."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wssi6cBmh12z"
   },
   "source": [
    "# Congratulations! Time to join the Community!\n",
    "\n",
    "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
    "\n",
    "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
    "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
    "\n",
    "## Join the DeepChem Gitter\n",
    "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pOBd6-YdQSvF"
   },
   "source": [
    "## Citing This Tutorial\n",
    "If you found this tutorial useful please consider citing it using the provided BibTeX. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZUk_9yIYw0c"
   },
   "outputs": [],
   "source": [
    "@manual{Intro8, \n",
    " title={Working With Splitters}, \n",
    " organization={DeepChem},\n",
    " author={Eastman, Peter and Ramsundar, Bharath}, \n",
    " howpublished = {\\url{https://github.com/deepchem/deepchem/blob/master/examples/tutorials/Working_With_Splitters.ipynb}}, \n",
    " year={2021}, \n",
    "} "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "06_Going_Deeper_on_Molecular_Featurizations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
