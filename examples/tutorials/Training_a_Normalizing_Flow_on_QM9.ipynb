{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BrLuyU3kMdt"
   },
   "source": [
    "# Tutorial Part ??: Training a Normalizing Flow on QM9\n",
    "By [Nathan C. Frey](https://ncfrey.github.io/) | [Twitter](https://twitter.com/nc_frey)\n",
    "\n",
    "\n",
    "In this tutorial, we will train a Normalizing Flow (NF) on the [QM9 dataset](https://www.nature.com/articles/sdata201422). The dataset comprises 133,885 stable small organic molecules made up of CHNOF atoms. We will try to train a network that is an invertible transformation between a simple base distribution and the distribution of molecules in QM9.  One of the key advantages of normalizing flows is that they can be constructed to efficiently sample from a distribution (generative modeling) and do probability density calculations (exactly compute log-likelihoods), whereas other models make tradeoffs between the two or can only approximate probability densities.\n",
    "\n",
    "NFs are useful whenever we need a probabilistic model with one or both of these capabilities. Note that because NFs are completely invertible, there is no \"latent space\" in the sense used when referring to generative adversarial networks or variational autoencoders. For more on NFs, we refer to this [review paper](https://arxiv.org/pdf/1912.02762.pdf).\n",
    "\n",
    "\n",
    "To encode the QM9 dataset, we'll make use of the SELFIES (SELF-referencIng Embedded Strings) representation, which is a 100% robust molecular string representation. SMILES strings produced by generative models are often syntactically invalid (they do not correspond to a molecular graph), or they violate chemical rules like the maximum number of bonds between atoms. SELFIES are designed so that even totally random SELFIES strings correspond to valid molecular graphs, so they are a great framework for generative modeling. For more details about SELFIES, see the [GitHub repo](https://github.com/aspuru-guzik-group/selfies) and the associated [paper](https://arxiv.org/abs/1905.13741).\n",
    "\n",
    "\n",
    "## Colab\n",
    "\n",
    "This tutorial and the rest in this sequence are designed to be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/23_Training_a_Normalizing_Flow_on_QM9.ipynb)\n",
    "\n",
    "## Setup\n",
    "\n",
    "To run DeepChem within Colab, you'll need to run the following cell of installation commands. This will take about 5 minutes to run to completion and install your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 124245,
     "status": "ok",
     "timestamp": 1600972940078,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "06FZl9Nqj_jq",
    "outputId": "e1d3f749-00ef-4b81-899e-99a66e4d737e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3490  100  3490    0     0  12690      0 --:--:-- --:--:-- --:--:-- 12690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "add /Users/alana/miniconda/lib/python3.7/site-packages to PYTHONPATH\n",
      "python version: 3.7.2\n",
      "remove current miniconda\n",
      "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "done\n",
      "installing miniconda to /Users/alana/miniconda\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['bash', 'Miniconda3-latest-Linux-x86_64.sh', '-b', '-p', '/Users/alana/miniconda']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-402465323f4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconda_installer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconda_installer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/miniconda/bin/conda info -e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepchem/examples/tutorials/conda_installer.py\u001b[0m in \u001b[0;36minstall\u001b[0;34m(chunk_size, file_name, url_base, conda_path, add_python_path, additional_channels, additional_packages)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'installing miniconda to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconda_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m   \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconda_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m   \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['bash', 'Miniconda3-latest-Linux-x86_64.sh', '-b', '-p', '/Users/alana/miniconda']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
    "import conda_installer\n",
    "conda_installer.install()\n",
    "!/root/miniconda/bin/conda info -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 130228,
     "status": "ok",
     "timestamp": 1600972946086,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "dVXJOn-p8Pld",
    "outputId": "8ec60872-e04f-4488-e0fd-9f1f16ccd670"
   },
   "outputs": [],
   "source": [
    "!pip install --pre deepchem\n",
    "import deepchem\n",
    "deepchem.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGVYBZh6Gq7N"
   },
   "source": [
    "Install the SELFIES library to translate SMILES strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135821,
     "status": "ok",
     "timestamp": 1600972951697,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "sqEygLk5GLYF",
    "outputId": "3df1490a-f23f-4ffc-8398-3dcc27770948"
   },
   "outputs": [],
   "source": [
    "!pip install selfies==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 136568,
     "status": "ok",
     "timestamp": 1600972952463,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "FpqPgmalHCdb",
    "outputId": "b1358a90-efea-45b3-8aff-0e43e82d46c0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import deepchem as dc\n",
    "from deepchem.models.normalizing_flows import NormalizingFlow, NormalizingFlowModel\n",
    "from deepchem.models.optimizers import Adam\n",
    "from deepchem.data import NumpyDataset\n",
    "from deepchem.splits import RandomSplitter\n",
    "from deepchem.molnet import load_tox21\n",
    "\n",
    "import rdkit\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import selfies as sf\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfk = tf.keras\n",
    "\n",
    "tfk.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYRunI2yHoLS"
   },
   "source": [
    "First, let's get a dataset of 2500 small organic molecules from the QM9 dataset. We'll then convert the molecules to SELFIES, one-hot encode them, and dequantize the inputs so they can be processed by a normalizing flow. 2000 molecules will be used for training, while the remaining 500 will be split into validation and test sets. We'll use the validation set to see how our architecture is doing at learning the underlying the distribution, and leave the test set alone. You should feel free to experiment with this notebook to get the best model you can and evaluate it on the test set when you're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803137,
     "status": "ok",
     "timestamp": 1600973619044,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "k2-L2gFHr04H"
   },
   "outputs": [],
   "source": [
    "# Download from MolNet\n",
    "tasks, datasets, transformers = dc.molnet.load_qm9(featurizer='ECFP')\n",
    "df = pd.DataFrame(data={'smiles': datasets[0].ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803152,
     "status": "ok",
     "timestamp": 1600973619064,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "fdo6CJMPGyig"
   },
   "outputs": [],
   "source": [
    "data = df[['smiles']].sample(2500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMh-1QUqCxkY"
   },
   "source": [
    "SELFIES defines a dictionary called `bond_constraints` that enforces how many bonds every atom or ion can make. E.g., 'C': 4, 'H': 1, etc. The `?` symbol is used for any atom or ion that isn't defined in the dictionary, and it defaults to 8 bonds. Because QM9 contains ions and we don't want to allow those ions to form up to 8 bonds, we'll constrain them to 3. This will really improve the percentage of valid molecules we generate. You can read more about setting constraints in the [SELFIES documentation](https://selfies-mirror.readthedocs.io/en/latest/selfies_examples.html#Advanced-Usage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803140,
     "status": "ok",
     "timestamp": 1600973619070,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "6cOS0cNTdb0I",
    "outputId": "d8fc1b88-0af7-4a82-e85c-889dbbcf8e86"
   },
   "outputs": [],
   "source": [
    "sf.set_semantic_constraints()  # reset constraints\n",
    "constraints = sf.get_semantic_constraints()\n",
    "constraints['?'] = 3\n",
    "\n",
    "sf.set_semantic_constraints(constraints)\n",
    "constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803139,
     "status": "ok",
     "timestamp": 1600973619075,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "2N5zUFvSV7uv"
   },
   "outputs": [],
   "source": [
    "def preprocess_smiles(smiles):\n",
    "  return sf.encoder(smiles)  \n",
    "\n",
    "data['selfies'] = data['smiles'].apply(preprocess_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rAriEcI7e5wl"
   },
   "source": [
    "Let's take a look at some short SMILES strings and their corresponding SELFIES representations. We can see right away that there is a key difference in how the two representations deal with Rings and Branches. SELFIES is designed so that branch length and ring size are stored locally with the `Branch` and `Ring` identifiers, and the SELFIES grammar prevents invalid strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803291,
     "status": "ok",
     "timestamp": 1600973619247,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "2dqSCmoPe30e",
    "outputId": "aa45a65e-10f1-4241-e974-816f3d395a5a"
   },
   "outputs": [],
   "source": [
    "data['len'] = data['smiles'].apply(lambda x: len(x))\n",
    "data.sort_values(by='len').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NrQelTLVa7wR"
   },
   "source": [
    "To convert SELFIES to a one-hot encoded representation, we need to construct an `alphabet` of all the characters that occur in the list of SELFIES strings. We also have to know what the longest SELFIES string is, so that all the shorter SELFIES can be padded with `'[nop]'` to be equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803461,
     "status": "ok",
     "timestamp": 1600973619421,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "BkQ0Sd3TY3Aq"
   },
   "outputs": [],
   "source": [
    "selfies_list = np.asanyarray(data.selfies)\n",
    "selfies_alphabet = sf.get_alphabet_from_selfies(selfies_list)\n",
    "selfies_alphabet.add('[nop]')  # Add the \"no operation\" symbol as a padding character\n",
    "selfies_alphabet = list(sorted(selfies_alphabet))\n",
    "symbol_to_idx = {s: i for i, s in enumerate(selfies_alphabet)}  # Dictionary matching selfies to index  \n",
    "largest_selfie_len = max(sf.len_selfies(s) for s in selfies_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQ2m_WoHt7_m"
   },
   "source": [
    "`selfies` has a handy utility function to translate SELFIES strings into one-hot encoded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803715,
     "status": "ok",
     "timestamp": 1600973619680,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "N9-d9yYMZSgI"
   },
   "outputs": [],
   "source": [
    "onehots = sf.selfies_to_encoding(selfies_list[0], vocab_stoi=symbol_to_idx, pad_to_len=largest_selfie_len, enc_type='one_hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "daU67TZZbbLa"
   },
   "source": [
    "Next, we \"dequantize\" the inputs by adding random noise from the interval `[0, 1)` to every input in the encodings. This allows the normalizing flow to operate on continuous inputs (rather than discrete), and the original inputs can easily be recovered by applying a floor function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807747,
     "status": "ok",
     "timestamp": 1600973623716,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "u3ThEWVcbvxn"
   },
   "outputs": [],
   "source": [
    "input_tensor = tf.convert_to_tensor(onehots, dtype='float64')\n",
    "noise_tensor = tf.random.uniform(shape=input_tensor.shape, minval=0, maxval=1, dtype='float64')\n",
    "dequantized_data = tf.add(input_tensor, noise_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B38gEbh6uLrr"
   },
   "source": [
    "The dequantized data is ready to be processed as a DeepChem dataset and split into training, validation, and test sets. We'll also keep track of the SMILES strings for the training set so we can compare the training data to our generated molecules later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807719,
     "status": "ok",
     "timestamp": 1600973623718,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "O3JqekV0HjNm",
    "outputId": "28d49000-e9d0-456b-b17f-29aa8ec53d68"
   },
   "outputs": [],
   "source": [
    "ds = NumpyDataset(dequantized_data)  # Create a DeepChem dataset\n",
    "splitter = RandomSplitter()\n",
    "train, val, test = splitter.train_valid_test_split(dataset=ds, seed=42)\n",
    "train_idx, val_idx, test_idx = splitter.split(dataset=ds, seed=42)\n",
    "\n",
    "dim = len(train.X[0])  # length of one-hot encoded vectors\n",
    "train.X.shape  # 2000 samples, N-dimensional one-hot vectors that represent molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807714,
     "status": "ok",
     "timestamp": 1600973623720,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "9In8bdWddovm"
   },
   "outputs": [],
   "source": [
    "# SMILES strings of training data\n",
    "train_smiles = data['smiles'].iloc[train_idx].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yZmmABKzI00F"
   },
   "source": [
    "Next we'll set up the normalizing flow model. The base distribution is a multivariate Normal distribution. The `permutation` layer permutes the dimensions of the input so that the normalizing flow layers will operate along multiple dimensions of the inputs. To understand why the permutation is needed, we need to know a bit about how the normalizing flow architecture works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807709,
     "status": "ok",
     "timestamp": 1600973623721,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "W_Ff2Q4rIyCe"
   },
   "outputs": [],
   "source": [
    "base_dist = tfd.MultivariateNormalDiag(loc=np.zeros(dim), scale_diag=np.ones(dim))\n",
    "\n",
    "if dim % 2 == 0:\n",
    "    permutation = tf.cast(np.concatenate((np.arange(dim / 2, dim), np.arange(0, dim / 2))),\n",
    "                                  tf.int32)\n",
    "else:\n",
    "    permutation = tf.cast(np.concatenate((np.arange(dim / 2 + 1, dim), np.arange(0, dim / 2))), tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMCyGvKKJwXw"
   },
   "source": [
    "For this simple example, we'll set up a flow of repeating [Masked Autoregressive Flow](https://arxiv.org/abs/1705.07057) layers. The autoregressive property is enforced by using the [Masked Autoencoder for Distribution Estimation](https://arxiv.org/abs/1502.03509) architecture. The layers of the flow are a bijector, an invertible mapping between the base and target distributions.\n",
    "\n",
    "MAF takes the inputs from the base distribution and transforms them with a simple scale-and-shift (affine) operation, but crucially the scale-and-shift for each dimension of the output *depends on the previously generated dimensions of the output.* That independence of future dimensions preserves the *autoregressive* property and ensures that the normalizing flow is invertible. Now we can see that we need permutations to change the ordering of the inputs, or else the normalizing flow would only transform certain dimensions of the inputs.\n",
    "\n",
    "Batch Normalization layers can be added for additional stability in training, but may have strange effects on the outputs and require some input reshaping to work properly. Increasing `num_layers` and `hidden_units` can make more expressive flows capable of modeling more complex target distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807703,
     "status": "ok",
     "timestamp": 1600973623723,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "byIooYBqJ2UC"
   },
   "outputs": [],
   "source": [
    "num_layers = 8\n",
    "flow_layers = []\n",
    "\n",
    "Made = tfb.AutoregressiveNetwork(params=2,\n",
    "                                 hidden_units=[512, 512], activation='relu')\n",
    "\n",
    "for i in range(num_layers):\n",
    "    flow_layers.append(        \n",
    "        (tfb.MaskedAutoregressiveFlow(shift_and_log_scale_fn=Made)\n",
    "    ))\n",
    "\n",
    "    permutation = tf.cast(np.random.permutation(np.arange(0, dim)), tf.int32)\n",
    "    \n",
    "    flow_layers.append(tfb.Permute(permutation=permutation))\n",
    "    \n",
    "#     if (i + 1) % int(2) == 0:\n",
    "#         flow_layers.append(tfb.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMbxkF_8KZxR"
   },
   "source": [
    "We can draw samples from the untrained distribution, but for now they don't have any relation to the QM9 dataset distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 843260,
     "status": "ok",
     "timestamp": 1600973659310,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "hBYNQrAYKQij",
    "outputId": "4bae2bf9-6d54-47fa-86b3-1b839b52e9fb"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nf = NormalizingFlow(base_distribution=base_dist,\n",
    "                    flow_layers=flow_layers)\n",
    "samples = nf.flow.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pa04f-1VcG0p"
   },
   "source": [
    "A `NormalizingFlowModel` takes a `NormalizingFlow` and any parameters used by `deepchem.models.KerasModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 843255,
     "status": "ok",
     "timestamp": 1600973659311,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "iA56ui2MK1QA"
   },
   "outputs": [],
   "source": [
    "nfm = NormalizingFlowModel(nf, learning_rate=1e-4, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IL-Onju8K8nK"
   },
   "source": [
    "Now to train the model! We'll try to minimize the negative log likelihood loss, which measures the likelihood that generated samples are drawn from the target distribution, i.e. as we train the model, it should get better at modeling the target distribution and it will generate samples that look like molecules from the QM9 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 843253,
     "status": "ok",
     "timestamp": 1600973659314,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "ZrmHYIHGK7-l"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1072102,
     "status": "ok",
     "timestamp": 1600973888187,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "vIURsPTpLZdh",
    "outputId": "592d9815-bd6e-457d-cc30-aff532b3b0ba"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "max_epochs = 20 # maximum number of epochs of the training\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "  loss = nfm.fit(train, nb_epoch=1, all_losses=losses)\n",
    "  val_loss = nfm.create_nll(val.X)\n",
    "  val_losses.append(val_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1072090,
     "status": "ok",
     "timestamp": 1600973888192,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "k33LyZsPNwUg",
    "outputId": "5a7f48c7-aa41-48c5-fe95-78b78cb23048"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.scatter(range(len(losses)), losses, label='train loss')\n",
    "ax.scatter(range(len(val_losses)), val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9k-x3QVMOVNr"
   },
   "source": [
    "The normalizing flow is learning a mapping between the multivariate Gaussian and the target distribution! We can see this by visualizing the loss on the validation set. We can now use `nfm.flow.sample()` to generate new QM9-like molecules and `nfm.flow.log_prob()` to evaluate the likelihood that a molecule was drawn from the underlying distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130180,
     "status": "ok",
     "timestamp": 1600973946286,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "mW8DeYFmOrJh"
   },
   "outputs": [],
   "source": [
    "generated_samples = nfm.flow.sample(50)  # generative modeling\n",
    "log_probs = nfm.flow.log_prob(generated_samples)  # probability density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0M2xaqcdYEc"
   },
   "source": [
    "Now we transform the generated samples back into SELFIES. We have to quantize the outputs and add padding characters to any one-hot encoding vector that has all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130183,
     "status": "ok",
     "timestamp": 1600973946294,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "DVVQ-dwWdXWb"
   },
   "outputs": [],
   "source": [
    "mols = tf.math.floor(generated_samples)  # quantize data\n",
    "mols = tf.clip_by_value(mols, 0, 1)  # Set negative values to 0 and values > 1 to 1\n",
    "mols_list = mols.numpy().tolist()\n",
    "\n",
    "# Add padding characters if needed\n",
    "for mol in mols_list:\n",
    "  if all(elem == 0 for elem in mol):\n",
    "    mol[-1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpwHYMP0LAvS"
   },
   "source": [
    "`selfies` has another utility function to translate one-hot encoded representations back to SELFIES strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130158,
     "status": "ok",
     "timestamp": 1600973946296,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "2XV-ZTgFjP04"
   },
   "outputs": [],
   "source": [
    "mols = sf.encoding_to_selfies(mols_list, selfies_alphabet, \"one_hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoC6RD8fdvVA"
   },
   "source": [
    "We can use RDKit to find valid generated molecules. Some have unphysical valencies and should be discarded. If you've ever tried to generate valid SMILES strings, you'll notice right away that this model is doing much better than we would expect! Using SELFIES, 90\\% of the generated molecules are valid, even though our normalizing flow architecture doesn't know any rules that govern chemical validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130134,
     "status": "ok",
     "timestamp": 1600973946297,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "F7EVnH9SdyN7",
    "outputId": "329baf39-cb2a-41d6-c468-9240a0349129"
   },
   "outputs": [],
   "source": [
    "from rdkit import RDLogger  \n",
    "from rdkit import Chem\n",
    "RDLogger.DisableLog('rdApp.*')  # suppress error messages\n",
    "\n",
    "valid_count = 0\n",
    "valid_selfies, invalid_selfies = [], []\n",
    "for idx, selfies in enumerate(mols):\n",
    "  try:\n",
    "    if Chem.MolFromSmiles(sf.decoder(mols[idx]), sanitize=True) is not None:\n",
    "        valid_count += 1\n",
    "        valid_selfies.append(selfies)\n",
    "    else:\n",
    "      invalid_selfies.append(selfies)\n",
    "  except Exception:\n",
    "    pass\n",
    "print('%.2f' % (valid_count / len(mols)),  'of generated samples are valid molecules.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pyt6ta2-d5Rd"
   },
   "source": [
    "Let's take a look at some of the generated molecules! We'll borrow some helper functions from the [Modeling Solubility](https://github.com/deepchem/deepchem/blob/master/examples/tutorials/03_Modeling_Solubility.ipynb) tutorial to display molecules with RDKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130119,
     "status": "ok",
     "timestamp": 1600973946300,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "XyE4CuaRe7BL"
   },
   "outputs": [],
   "source": [
    "gen_mols = [Chem.MolFromSmiles(sf.decoder(vs)) for vs in valid_selfies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130113,
     "status": "ok",
     "timestamp": 1600973946301,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "JehQTBLXd9Gn"
   },
   "outputs": [],
   "source": [
    "def display_images(filenames):\n",
    "    \"\"\"Helper to pretty-print images.\"\"\"\n",
    "    for file in filenames:\n",
    "      display(Image(file))\n",
    "\n",
    "def mols_to_pngs(mols, basename=\"generated_mol\"):\n",
    "    \"\"\"Helper to write RDKit mols to png files.\"\"\"\n",
    "    filenames = []\n",
    "    for i, mol in enumerate(mols):\n",
    "        filename = \"%s%d.png\" % (basename, i)\n",
    "        Draw.MolToFile(mol, filename)\n",
    "        filenames.append(filename)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130349,
     "status": "ok",
     "timestamp": 1600973946557,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "oyWxxxqvnKGf",
    "outputId": "8e039e2f-ebe2-4143-cde8-f1303fe3ba71"
   },
   "outputs": [],
   "source": [
    "display_mols = []\n",
    "for i in range(10):\n",
    "  display_mols.append(gen_mols[i])\n",
    "\n",
    "display_images(mols_to_pngs(display_mols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2R5K7Y5hedbW"
   },
   "source": [
    "Finally, we can compare generated molecules with our training data via a [similarity search](https://medium.com/gsi-technology/rdkit-for-newbies-3697e617521f) with Tanimoto similarity. This gives an indication of how \"original\" the generated samples are, versus simply producing samples that are extremely similar to molecules the model has already seen. We have to keep in mind that QM9 contains *all* stable small molecules with up to 9 heavy atoms (CONF). So anything new we generate either exists in the full QM9 dataset, or else will not obey the charge neutrality and stability criteria used to generated QM9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130347,
     "status": "ok",
     "timestamp": 1600973946559,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "RE_vIKDke3Vd"
   },
   "outputs": [],
   "source": [
    "from rdkit.Chem.Fingerprints.FingerprintMols import FingerprintMol\n",
    "from rdkit.DataStructs import FingerprintSimilarity\n",
    "from IPython.display import display\n",
    "\n",
    "def tanimoto_similarity(database_mols, query_mol):\n",
    "    \"\"\"Compare generated molecules to database by Tanimoto similarity.\"\"\"\n",
    "    # convert Mol to datastructure type\n",
    "    fps = [FingerprintMol(m) for m in database_mols]\n",
    "    \n",
    "    # set a query molecule to compare against database\n",
    "    query = FingerprintMol(query_mol)\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    # loop through to find Tanimoto similarity\n",
    "    for idx, f in enumerate(fps):\n",
    "        # tuple: (idx, similarity)\n",
    "        similarities.append((idx, FingerprintSimilarity(query, f)))\n",
    "    \n",
    "    # sort sim using the similarities\n",
    "    similarities.sort(key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCPEN3_cfQ4N"
   },
   "source": [
    "We'll consider our generated molecules and look at the top 3 most similar molecules from the training data by Tanimoto similarity. Here's an example where the Tanimoto similarity scores are low! There are no molecules in our training set that are very similar to our generated sample. This might be interesting, or it might mean that the generated molecule is unrealistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130525,
     "status": "ok",
     "timestamp": 1600973946741,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "MjR0O1EucwC3"
   },
   "outputs": [],
   "source": [
    "train_mols = [Chem.MolFromSmiles(smiles) for smiles in train_smiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1600976249046,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "vsaSkVJufGDy"
   },
   "outputs": [],
   "source": [
    "# change the second argument to compare different generated molecules to QM9\n",
    "tanimoto_scores = tanimoto_similarity(train_mols, gen_mols[3])\n",
    "similar_mols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 967
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1600976249858,
     "user": {
      "displayName": "Nathan Frey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCEtTj6AL3entEShxjitkGUQo5YhZ7CJA0917VzA=s64",
      "userId": "14838914823565259795"
     },
     "user_tz": 240
    },
    "id": "zgyJ9txQsRxg",
    "outputId": "8c07c35c-a575-4919-dd0e-c89ec7a1d6e2"
   },
   "outputs": [],
   "source": [
    "for idx, ts in tanimoto_scores[:3]:\n",
    "    print(round(ts, 3))\n",
    "    similar_mols.append(train_mols[idx])\n",
    "\n",
    "display_images(mols_to_pngs(similar_mols, 'qm9_mol'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oyYuK11xxBO"
   },
   "source": [
    "### Further reading\n",
    "\n",
    "So far we have looked at a measure of validity and done a bit of investigation into the novelty of the generated compounds. There are more dimensions along which we can and should evaluate the performance of a generative model. For an example of some standard benchmarks, see the [GuacaMol evaluation framework](https://arxiv.org/pdf/1811.09621.pdf).\n",
    "\n",
    "For examples of normalizing flow-based molecular graph generation frameworks, check out the [MoFlow](https://arxiv.org/abs/2006.10137), [GraphAF](https://arxiv.org/pdf/2001.09382.pdf), and [GraphNVP](https://arxiv.org/pdf/1905.11600.pdf) papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdJAF3aEHGbV"
   },
   "source": [
    "# Congratulations! Time to join the Community!\n",
    "\n",
    "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
    "\n",
    "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
    "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
    "\n",
    "## Join the DeepChem Gitter\n",
    "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNyrrTvEu36LoiXsM0a4+4b",
   "collapsed_sections": [],
   "name": "Training_a_Normalizing_Flow_on_QM9.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
