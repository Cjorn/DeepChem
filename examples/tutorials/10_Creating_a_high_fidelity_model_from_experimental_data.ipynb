{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6MNHvkiBl55x"
   },
   "source": [
    "# Tutorial Part 10: Creating a High Fidelity Dataset from Experimental Data\n",
    "\n",
    "In this tutorial, we will look at what is involved in creating a new Dataset from experimental data.  As we will see, the mechanics of creating the Dataset object is only a small part of the process.  Most real datasets need significant cleanup and QA before they are suitable for training models.\n",
    "\n",
    "## Colab\n",
    "\n",
    "This tutorial and the rest in this sequence are designed to be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/10_Creating_a_high_fidelity_model_from_experimental_data.ipynb)\n",
    "\n",
    "## Setup\n",
    "\n",
    "To run DeepChem within Colab, you'll need to run the following installation commands. This will take about 5 minutes to run to completion and install your environment. You can of course run this tutorial locally if you prefer. In that case, don't run these cells since they will download and install Anaconda on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "tbLbuh6wl8tX",
    "outputId": "5ddc020c-80ff-42fe-fe5b-85dd0b25446f"
   },
   "outputs": [],
   "source": [
    "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
    "import conda_installer\n",
    "conda_installer.install()\n",
    "!/root/miniconda/bin/conda info -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "iR6NiQ6rLqbK",
    "outputId": "5c2fb16e-80c3-40c7-9a05-2e9e3c397a99"
   },
   "outputs": [],
   "source": [
    "!pip install --pre deepchem\n",
    "import deepchem\n",
    "deepchem.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpVK4q5Ol558"
   },
   "source": [
    "## Working With Data Files\n",
    "\n",
    "Suppose you were given data collected by an experimental collaborator.  You would like to use this data to construct a machine learning model. \n",
    "\n",
    "*How do you transform this data into a dataset capable of creating a useful model?*\n",
    "\n",
    "Building models from novel data can present several challenges.  Perhaps the data was not recorded in a convenient manner.  Additionally, perhaps the data contains noise.  This is a common occurrence with, for example, biological assays due to the large number of external variables and the difficulty and cost associated with collecting multiple samples.  This is a problem because you do not want your model to fit to this noise.\n",
    "\n",
    "Hence, there are two primary challenges:\n",
    "* Parsing data\n",
    "* De-noising data\n",
    "\n",
    "In this tutorial, we will walk through an example of curating a dataset from an excel spreadsheet of experimental drug  measurements. Before we dive into this example though, let's do a brief review of DeepChem's input file handling and featurization capabilities.\n",
    "\n",
    "### Input Formats\n",
    "DeepChem supports a whole range of input files. For example, accepted input formats include .csv, .sdf, .fasta, .png, .tif and other file formats. The loading for a particular file format is governed by the `Loader` class associated with that format. For example, to load a .csv file we use the `CSVLoader` class. Here's an example of a .csv file that fits the requirements of `CSVLoader`.\n",
    "\n",
    "1. A column containing SMILES strings.\n",
    "2. A column containing an experimental measurement.\n",
    "3. (Optional) A column containing a unique compound identifier.\n",
    "\n",
    "Here's an example of a potential input file.\n",
    "\n",
    "|Compound ID    | measured log solubility in mols per litre | smiles         |\n",
    "|---------------|-------------------------------------------|----------------|\n",
    "| benzothiazole | -1.5                                      | c2ccc1scnc1c2  |\n",
    "\n",
    "\n",
    "Here the \"smiles\" column contains the SMILES string, the \"measured log\n",
    "solubility in mols per litre\" contains the experimental measurement, and\n",
    "\"Compound ID\" contains the unique compound identifier.\n",
    "\n",
    "### Data Featurization \n",
    "\n",
    "Most machine learning algorithms require that input data form vectors. However, input data for drug-discovery datasets routinely come in the form of lists of molecules and associated experimental readouts. To load the data, we use a subclass of `dc.data.DataLoader` such as `dc.data.CSVLoader` or `dc.data.SDFLoader`. Users can subclass `dc.data.DataLoader` to load arbitrary file formats. All loaders must be passed a `dc.feat.Featurizer` object, which specifies how to transform molecules into vectors. DeepChem provides a number of different subclasses of `dc.feat.Featurizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-rrEZ5ihl56A"
   },
   "source": [
    "## Parsing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0AhOo1nl56D"
   },
   "source": [
    "In order to read in the data, we will use the pandas data analysis library.  \n",
    "\n",
    "In order to convert the drug names into smiles strings, we will use pubchempy. This isn't a standard DeepChem dependency, but you can install this library with `conda install -c mcs07 pubchempy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "fYBi59mkl56F",
    "outputId": "8536d712-eedf-411c-859c-4db4f7204dfa"
   },
   "outputs": [],
   "source": [
    "!conda install -c mcs07 pubchempy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gj-VYSail56Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pubchempy import get_cids, get_compounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwhTD4OBl56V"
   },
   "source": [
    "Pandas is magic but it doesn't automatically know where to find your data of interest.  You likely will have to look at it first using a GUI.  \n",
    "\n",
    "We will now look at a screenshot of this dataset as rendered by LibreOffice.\n",
    "\n",
    "To do this, we will import Image and os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6CrNCoe0l56s"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "current_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "data_screenshot = os.path.join(current_dir, 'assets/dataset_preparation_gui.png')\n",
    "display(Image(filename=data_screenshot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ud2cRDy_l566"
   },
   "source": [
    "We see the data of interest is on the second sheet, and contained in columns \"TA ID\", \"N #1 (%)\", and \"N #2 (%)\".\n",
    "\n",
    "Additionally, it appears much of this spreadsheet was formatted for human readability (multicolumn headers, column labels with spaces and symbols, etc.).  This makes the creation of a neat dataframe object harder.  For this reason we will cut everything that is unnecesary or inconvenient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "hVJDAGT8mbl1",
    "outputId": "52892aeb-f4e9-4a03-a7a3-1edaf512aa0d"
   },
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "dc.utils.download_url(\n",
    "    'https://github.com/deepchem/deepchem/raw/master/datasets/Positive%20Modulators%20Summary_%20918.TUC%20_%20v1.xlsx',\n",
    "    current_dir,\n",
    "    'Positive Modulators Summary_ 918.TUC _ v1.xlsx'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse .xlsx files the xlrd and openpyxl module must pe installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xlrd openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMvd0XzRl567"
   },
   "outputs": [],
   "source": [
    "raw_data_file = os.path.join(current_dir, 'Positive Modulators Summary_ 918.TUC _ v1.xlsx')\n",
    "raw_data_excel = pd.ExcelFile(raw_data_file, engine='openpyxl')\n",
    "\n",
    "# second sheet only\n",
    "raw_data = raw_data_excel.parse(raw_data_excel.sheet_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ei2QwtnVl57D",
    "outputId": "39406331-090a-4537-d9fd-74b9ba46172d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preview 5 rows of raw dataframe\n",
    "raw_data.loc[raw_data.index[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kfGr4zPSl57Q"
   },
   "source": [
    "Note that the actual row headers are stored in row 1 and not 0 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "adUjxQF2l57Z",
    "outputId": "976bffc4-5792-4ba4-882d-660525ba229f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove column labels (rows 0 and 1), as we will replace them\n",
    "# only take data given in columns \"TA ID\" \"N #1 (%)\" (3) and \"N #2 (%)\" (4)\n",
    "raw_data = raw_data.iloc[2:, [2, 6, 7]]\n",
    "\n",
    "# reset the index so we keep the label but number from 0 again\n",
    "raw_data.reset_index(inplace=True)\n",
    "\n",
    "## rename columns\n",
    "raw_data.columns = ['label', 'drug', 'n1', 'n2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "_AmIYJGjl57j",
    "outputId": "402dd41a-d077-44d0-ed6f-dad28e0cef3b"
   },
   "outputs": [],
   "source": [
    "# preview cleaner dataframe\n",
    "raw_data.loc[raw_data.index[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Htu9Bw6l57p"
   },
   "source": [
    "This formatting is closer to what we need.\n",
    "\n",
    "Now, let's take the drug names and get smiles strings for them (format needed for DeepChem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hGrrqu5l57q"
   },
   "outputs": [],
   "source": [
    "drugs = raw_data['drug'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJAABOqPl57y"
   },
   "source": [
    "For many of these, we can retreive the smiles string via the canonical_smiles attribute of the `get_compounds` object (using `pubchempy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yfCp2htdl570",
    "outputId": "7ec9923b-02ea-42ce-b98d-fb80fd684626"
   },
   "outputs": [],
   "source": [
    "get_compounds(drugs[1], 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rsesx-l8l58L",
    "outputId": "6f087c85-b3bc-4a56-f052-3b463e9d71aa"
   },
   "outputs": [],
   "source": [
    "get_compounds(drugs[1], 'name')[0].canonical_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4qqWsWZl581"
   },
   "source": [
    "However, some of these drug names have variables spaces and symbols (·, (±), etc.), and names that may not be readable by pubchempy. \n",
    "\n",
    "For this task, we will do a bit of hacking via regular expressions.  Also, we notice that all ions are written in a shortened form that will need to be expanded.  For this reason we use a dictionary, mapping the shortened ion names to versions recognizable to pubchempy.  \n",
    "\n",
    "Unfortunately you may have several corner cases that will require more hacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGch_fRUl587"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ion_replacements = {\n",
    "    'HBr': ' hydrobromide',\n",
    "    '2Br': ' dibromide',\n",
    "    'Br': ' bromide',\n",
    "    'HCl': ' hydrochloride',\n",
    "    '2H2O': ' dihydrate',\n",
    "    'H20': ' hydrate',\n",
    "    'Na': ' sodium'\n",
    "}\n",
    "\n",
    "ion_keys = ['H20', 'HBr', 'HCl', '2Br', '2H2O', 'Br', 'Na']\n",
    "\n",
    "def compound_to_smiles(cmpd):\n",
    "    # remove spaces and irregular characters\n",
    "    compound = re.sub(r'([^\\s\\w]|_)+', '', cmpd)\n",
    "                   \n",
    "    # replace ion names if needed\n",
    "    for ion in ion_keys:\n",
    "        if ion in compound:\n",
    "            compound = compound.replace(ion, ion_replacements[ion])\n",
    "\n",
    "    # query for cid first in order to avoid timeouterror\n",
    "    cid = get_cids(compound, 'name')[0]\n",
    "    smiles = get_compounds(cid)[0].canonical_smiles\n",
    "\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-qPqmm3l59s"
   },
   "source": [
    "Now let's actually convert all these compounds to smiles. This conversion will take a few minutes so might not be a bad spot to go grab a coffee or tea and take a break while this is running! Note that this conversion will sometimes fail so we've added some error handling to catch these cases below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "PMlMlVJTl59t",
    "outputId": "cf54a840-fb35-4904-c96e-e016ab7c1935",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smiles_map = {}\n",
    "for i, compound in enumerate(drugs):\n",
    "    try:\n",
    "        smiles_map[compound] = compound_to_smiles(compound)\n",
    "    except:\n",
    "        print(\"Errored on %s\" % i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgPwj-Pvl594"
   },
   "outputs": [],
   "source": [
    "smiles_data = raw_data\n",
    "# map drug name to smiles string\n",
    "smiles_data['drug'] = smiles_data['drug'].apply(lambda x: smiles_map[x] if x in smiles_map else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "xV3mQWwrl5-v",
    "outputId": "e031e783-4912-468f-abbb-64225e6b1ec6"
   },
   "outputs": [],
   "source": [
    "# preview smiles data\n",
    "smiles_data.loc[smiles_data.index[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ES-ak26xl5-1"
   },
   "source": [
    "Hooray, we have mapped each drug name to its corresponding smiles code.\n",
    "\n",
    "Now, we need to look at the data and remove as much noise as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghu-RpSCl5-3"
   },
   "source": [
    "## De-noising data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axbec0-Dl5-4"
   },
   "source": [
    "In machine learning, we know that there is no free lunch.  You will need to spend time analyzing and understanding your data in order to frame your problem and determine the appropriate model framework.  Treatment of your data will depend on the conclusions you gather from this process.\n",
    "\n",
    "Questions to ask yourself:\n",
    "* What are you trying to accomplish?\n",
    "* What is your assay?\n",
    "* What is the structure of the data?\n",
    "* Does the data make sense?\n",
    "* What has been tried previously?\n",
    "\n",
    "For this project (respectively):\n",
    "* I would like to build a model capable of predicting the affinity of an arbitrary small molecule drug to a particular ion channel protein\n",
    "* For an input drug, data describing channel inhibition\n",
    "* A few hundred drugs, with n=2\n",
    "* Will need to look more closely at the dataset*\n",
    "* Nothing on this particular protein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ls_jIMqUl5-5"
   },
   "source": [
    "*This will involve plotting, so we will import matplotlib and seaborn.  We will also need to look at molecular structures, so we will import rdkit. We will also use the seaborn library which you can install with `conda install seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Xe0sqLZ0l5-6",
    "outputId": "4e1a4198-0617-4159-e193-8c3e485de045"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw, PyMol, rdFMCS\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import rdBase\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fKzIHFnl5_K"
   },
   "source": [
    "Our goal is to build a small molecule model, so let's make sure our molecules are all small.  This can be approximated by the length of each smiles string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "HZjb8u_fl5_S",
    "outputId": "136daa91-c521-4d32-e204-bbb05eec8149"
   },
   "outputs": [],
   "source": [
    "smiles_data['len'] = [len(i) if i is not None else 0 for i in smiles_data['drug']]\n",
    "smiles_lens = [len(i) if i is not None else 0 for i in smiles_data['drug']]\n",
    "sns.histplot(smiles_lens)\n",
    "plt.xlabel('len(smiles)')\n",
    "plt.ylabel('probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmKR_T4Vl5_X"
   },
   "source": [
    "Some of these look rather large, len(smiles) > 150.  Let's see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2H-4P1ol5_Y"
   },
   "outputs": [],
   "source": [
    "# indices of large looking molecules\n",
    "suspiciously_large = np.where(np.array(smiles_lens) > 150)[0]\n",
    "\n",
    "# corresponding smiles string\n",
    "long_smiles = smiles_data.loc[smiles_data.index[suspiciously_large]]['drug'].values\n",
    "\n",
    "# look\n",
    "Draw._MolsToGridImage([Chem.MolFromSmiles(i) for i in long_smiles], molsPerRow=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kazyeOPYl5_i"
   },
   "source": [
    "As suspected, these are not small molecules, so we will remove them from the dataset.  The argument here is that these molecules could register as inhibitors simply because they are large.  They are more likely to sterically blocks the channel, rather than diffuse inside and bind (which is what we are interested in).\n",
    "\n",
    "The lesson here is to remove data that does not fit your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkFF2eMgl5_j"
   },
   "outputs": [],
   "source": [
    "# drop large molecules\n",
    "smiles_data = smiles_data[~smiles_data['drug'].isin(long_smiles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjSLGiv0l5_m"
   },
   "source": [
    "Now, let's look at the numerical structure of the dataset.\n",
    "\n",
    "First, check for NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "H5wkbrWgl5_n",
    "outputId": "a4b2e5eb-4feb-40e4-b12d-e1f28dc2d3b7"
   },
   "outputs": [],
   "source": [
    "nan_rows = smiles_data[smiles_data.isnull().T.any().T]\n",
    "nan_rows[['n1', 'n2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6xL_ztsl5_u"
   },
   "source": [
    "I don't trust n=1, so I will throw these out.  \n",
    "\n",
    "Then, let's examine the distribution of n1 and n2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "txAjPzOAl5_2",
    "outputId": "6679981a-60cd-473f-f6fb-86166d7c5b5e"
   },
   "outputs": [],
   "source": [
    "df = smiles_data.dropna(axis=0, how='any')\n",
    "# seaborn jointplot will allow us to compare n1 and n2, and plot each marginal\n",
    "sns.jointplot(x='n1', y='n2', data=smiles_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqNjNcTNl5_7"
   },
   "source": [
    "We see that most of the data is contained in the gaussian-ish blob centered a bit below zero.  We see that there are a few clearly active datapoints located in the bottom left, and one on the top right.  These are all distinguished from the majority of the data.  How do we handle the data in the blob?  \n",
    "\n",
    "Because n1 and n2 represent the same measurement, ideally they would be of the same value.  This plot should be tightly aligned to the diagonal, and the pearson correlation coefficient should be 1.  We see this is not the case.  This helps gives us an idea of the error of our assay.\n",
    "\n",
    "Let's look at the error more closely, plotting in the distribution of (n1-n2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "guGcilXIl5_9",
    "outputId": "89bcc713-0d04-443d-eda0-19deb9abf560"
   },
   "outputs": [],
   "source": [
    "diff_df = df['n1'] - df['n2']\n",
    "\n",
    "sns.histplot(diff_df)\n",
    "plt.xlabel('difference in n')\n",
    "plt.ylabel('probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VTbA5r_Zl6AD"
   },
   "source": [
    "This looks pretty gaussian, let's get the 95% confidence interval by fitting a gaussian via scipy, and taking 2*the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PcBDorCcl6AS",
    "outputId": "ee99844a-4b00-4056-bc5b-ee4282a5172d"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "mean, std = stats.norm.fit(np.asarray(diff_df, dtype=np.float32))\n",
    "ci_95 = std*2\n",
    "ci_95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_6SzWXyl6Ak"
   },
   "source": [
    "Now, I don't trust the data outside of the confidence interval, and will therefore drop these datapoints from df.  \n",
    "\n",
    "For example, in the plot above, at least one datapoint has n1-n2 > 60.  This is disconcerting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "qR8D_BKel6Ay",
    "outputId": "c5f59a48-4780-4883-a3fa-b47320071f6c"
   },
   "outputs": [],
   "source": [
    "noisy = diff_df[abs(diff_df) > ci_95]\n",
    "df = df.drop(noisy.index)\n",
    "sns.jointplot(x='n1', y='n2', data=df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oORmeyHNl6A1"
   },
   "source": [
    "Now that data looks much better!\n",
    "\n",
    "So, let's average n1 and n2, and take the error bar to be ci_95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "7NsMKc6Nl6A3",
    "outputId": "cef1fc9d-6b55-403a-c0c5-97cd92303624"
   },
   "outputs": [],
   "source": [
    "avg_df = df[['label', 'drug']].copy()\n",
    "n_avg = df[['n1', 'n2']].mean(axis=1)\n",
    "avg_df['n'] = n_avg\n",
    "avg_df.sort_values('n', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIUv_SV2l6A7"
   },
   "source": [
    "Now, let's look at the sorted data with error bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "YN1DgKJNl6BD",
    "outputId": "23bb0034-c1c8-4a91-b915-48d2a76a2e6c"
   },
   "outputs": [],
   "source": [
    "plt.errorbar(np.arange(avg_df.shape[0]), avg_df['n'], yerr=ci_95, fmt='o')\n",
    "plt.xlabel('drug, sorted')\n",
    "plt.ylabel('activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NxsJUoS0l6BH"
   },
   "source": [
    "Now, let's identify our active compounds.  \n",
    "\n",
    "In my case, this required domain knowledge.  Having worked in this area, and having consulted with professors specializing on this channel, I am interested in compounds where the absolute value of the activity is greater than 25.  This relates to the desired drug potency we would like to model.\n",
    "\n",
    "If you are not certain how to draw the line between active and inactive, this cutoff could potentially be treated as a hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "MQPUH1ogl6BH",
    "outputId": "c6874a35-23f1-4a7d-e4ac-6a7fc90fc32a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "actives = avg_df[abs(avg_df['n'])-ci_95 > 25]['n']\n",
    "\n",
    "plt.errorbar(np.arange(actives.shape[0]), actives, yerr=ci_95, fmt='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9rz2KjJ8l6BS",
    "outputId": "ebeac3f3-091b-4e99-ac7d-8bfec5f59aac"
   },
   "outputs": [],
   "source": [
    "# summary\n",
    "print (raw_data.shape, avg_df.shape, len(actives.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TiNqzX0Kl6BV"
   },
   "source": [
    "In summary, we have:\n",
    "* Removed data that did not address the question we hope to answer (small molecules only)\n",
    "* Dropped NaNs\n",
    "* Determined the noise of our measurements\n",
    "* Removed exceptionally noisy datapoints\n",
    "* Identified actives (using domain knowledge to determine a threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46rf9hMkl6BW"
   },
   "source": [
    "## Determine model type, final form of dataset, and sanity load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUK150zHl6BX"
   },
   "source": [
    "Now, what model framework should we use?  \n",
    "\n",
    "Given that we have 392 datapoints and 6 actives, this data will be used to build a low data one-shot classifier (10.1021/acscentsci.6b00367).  If there were datasets of similar character, transfer learning could potentially be used, but this is not the case at the moment.\n",
    "\n",
    "\n",
    "Let's apply logic to our dataframe in order to cast it into a binary format, suitable for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "WwcvCbigl6BX",
    "outputId": "a7e8abc2-f738-401d-9e1e-f4eb3238ba8b"
   },
   "outputs": [],
   "source": [
    "# 1 if condition for active is met, 0 otherwise\n",
    "avg_df.loc[:, 'active'] = (abs(avg_df['n'])-ci_95 > 25).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2t7vmHnNl6Bc"
   },
   "source": [
    "Now, save this to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6AGQoB2l6Be"
   },
   "outputs": [],
   "source": [
    "avg_df.to_csv('modulators.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vs7Pkg7Il6Bp"
   },
   "source": [
    "Now, we will convert this dataframe to a DeepChem dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "NRpnbgyAl6Bv",
    "outputId": "9f37a491-24cc-4a2c-af7c-23d1dd42e72c"
   },
   "outputs": [],
   "source": [
    "dataset_file = 'modulators.csv'\n",
    "task = ['active']\n",
    "featurizer_func = dc.feat.ConvMolFeaturizer()\n",
    "\n",
    "loader = dc.data.CSVLoader(tasks=task, feature_field='drug', featurizer=featurizer_func)\n",
    "dataset = loader.create_dataset(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D9GElTwzl6B0"
   },
   "source": [
    "Lastly, it is often advantageous to numerically transform the data in some way.  For example, sometimes it is useful to normalize the data, or to zero the mean.  This depends in the task at hand.\n",
    "\n",
    "Built into DeepChem are many useful transformers, located in the deepchem.transformers.transformers base class. \n",
    "\n",
    "Because this is a classification model, and the number of actives is low, I will apply a balancing transformer.  I treated this transformer as a hyperparameter when I began training models.  It proved to unambiguously improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ll5i93il6B1"
   },
   "outputs": [],
   "source": [
    "transformer = dc.trans.BalancingTransformer(dataset=dataset)\n",
    "dataset = transformer.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L57S8x7sl6B4"
   },
   "source": [
    "Now let's save the balanced dataset object to disk, and then reload it as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwFyB7Ryl6B5"
   },
   "outputs": [],
   "source": [
    "dc.utils.save_to_disk(dataset, 'balanced_dataset.joblib')\n",
    "balanced_dataset = dc.utils.load_from_disk('balanced_dataset.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oydv-y4Fl6B9"
   },
   "source": [
    "Tutorial written by Keri McKiernan (github.com/kmckiern) on September 8, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2E5bL1Jl6CD"
   },
   "source": [
    "# Congratulations! Time to join the Community!\n",
    "\n",
    "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
    "\n",
    "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
    "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
    "\n",
    "## Join the DeepChem Gitter\n",
    "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!\n",
    "\n",
    "\n",
    "# Bibliography\n",
    "\n",
    "[2] Anderson, Eric, Gilman D. Veith, and David Weininger. \"SMILES, a line\n",
    "notation and computerized interpreter for chemical structures.\" US\n",
    "Environmental Protection Agency, Environmental Research Laboratory, 1987."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "09_Creating_a_high_fidelity_model_from_experimental_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
