{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using DeepChem with Tensorflow Data and Estimators\n",
    "-----------------------------------------------\n",
    "\n",
    "When DeepChem was first created, Tensorflow had no standard interface for datasets or models.  We created the Dataset and Model classes to fill this hole.  More recently, Tensorflow has added the `tf.data` module as a standard interface for datasets, and the `tf.estimator` module as a standard interface for models.  To enable easy interoperability with other tools, we have added features to Dataset and Model to support these new standards.\n",
    "\n",
    "This example demonstrates how to use these features.  Let's begin by loading a dataset and creating a model to analyze it.  We'll use a simple MultiTaskClassifier with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leswing/miniconda3/envs/deepchem/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_tox21()\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "n_tasks = len(tasks)\n",
    "n_features = train_dataset.X.shape[1]\n",
    "\n",
    "model = dc.models.MultiTaskClassifier(n_tasks, n_features, layer_sizes=[1000], dropouts=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train the model using the training set, then evaluate it on the test set.  As our evaluation metric we will use the ROC AUC, averaged over the 12 tasks included in the dataset.  First let's see how to do this with the DeepChem API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.7128020660394763, 0.8559545888832687, 0.8320876426058216, 0.7769258949131252, 0.6964857622170417, 0.7878628628628628, 0.7187810327706057, 0.6729681301839163, 0.7889239861422458, 0.7391541694133157, 0.8305204522780181, 0.725944660014782]\n",
      "{'mean-roc_auc_score': 0.7615342706937067}\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 100\n",
    "model.fit(train_dataset, nb_epoch=NB_EPOCH)\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "print(model.evaluate(test_dataset, [metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple enough.  Now let's see how to do the same thing with the Tensorflow APIs.  Fair warning: this is going to take a lot more code!\n",
    "\n",
    "To begin with, Tensorflow doesn't allow a dataset to be passed directly to a model.  Instead, you need to write an \"input function\" to construct a particular set of tensors and return them in a particular format.  Fortunately, Dataset's `make_iterator()` method provides exactly the tensors we need in the form of a `tf.data.Iterator`.  This allows our input function to be very simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(dataset, epochs):\n",
    "    x, y, weights = dataset.make_iterator(batch_size=100, epochs=epochs).get_next()\n",
    "    return {'x': x, 'weights': weights}, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you have to use the functions in the `tf.feature_column` module to create an object representing each feature and weight column (but curiously, *not* the label columnâ€”don't ask me why!).  These objects describe the data type and shape of each column, and give each one a name.  The names must match the keys in the dict returned by the input function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = tf.feature_column.numeric_column('x', shape=(n_features,))\n",
    "weight_col = tf.feature_column.numeric_column('weights', shape=(n_tasks,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike DeepChem models, which allow arbitrary metrics to be passed to `evaluate()`, estimators require all metrics to be defined up front when you create the estimator.  Unfortunately, Tensorflow doesn't have very good support for multitask models.  It provides an AUC metric, but no easy way to average this metric over tasks.  We therefore must create a separate metric for every task, then define our own metric function to compute the average of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_auc(labels, predictions, weights):\n",
    "    metric_ops = []\n",
    "    update_ops = []\n",
    "    for i in range(n_tasks):\n",
    "        metric, update = tf.metrics.auc(labels[:,i], predictions[:,i], weights[:,i])\n",
    "        metric_ops.append(metric)\n",
    "        update_ops.append(update)\n",
    "    mean_metric = tf.reduce_mean(tf.stack(metric_ops))\n",
    "    update_all = tf.group(*update_ops)\n",
    "    return mean_metric, update_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create our `Estimator` by calling `make_estimator()` on the DeepChem model.  We provide as arguments the objects created above to represent the feature and weight columns, as well as our metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'estimator', '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_master': '', '_task_id': 0, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_tf_random_seed': None, '_is_chief': True, '_evaluation_master': '', '_service': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_task_type': 'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5540673080>, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = model.make_estimator(feature_columns=[x_col],\n",
    "                                 weight_column=weight_col,\n",
    "                                 metrics={'mean_auc': mean_auc},\n",
    "                                 model_dir='estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to train and evaluate it!  Notice how the input function passed to each method is actually a lambda.  This allows us to write a single function, then use it with different datasets and numbers of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 1705.3706, step = 1\n",
      "INFO:tensorflow:global_step/sec: 127.053\n",
      "INFO:tensorflow:loss = 842.8985, step = 101 (0.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.566\n",
      "INFO:tensorflow:loss = 535.6992, step = 201 (1.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.348\n",
      "INFO:tensorflow:loss = 653.16656, step = 301 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.3015\n",
      "INFO:tensorflow:loss = 498.91153, step = 401 (1.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.61\n",
      "INFO:tensorflow:loss = 706.3443, step = 501 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.823\n",
      "INFO:tensorflow:loss = 438.93698, step = 601 (1.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.2487\n",
      "INFO:tensorflow:loss = 397.8996, step = 701 (1.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.068\n",
      "INFO:tensorflow:loss = 391.56342, step = 801 (0.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.4284\n",
      "INFO:tensorflow:loss = 323.1883, step = 901 (1.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.434\n",
      "INFO:tensorflow:loss = 311.08008, step = 1001 (0.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7353\n",
      "INFO:tensorflow:loss = 348.38126, step = 1101 (1.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0247\n",
      "INFO:tensorflow:loss = 273.6717, step = 1201 (1.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.723\n",
      "INFO:tensorflow:loss = 293.05487, step = 1301 (0.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.0908\n",
      "INFO:tensorflow:loss = 207.26912, step = 1401 (1.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.662\n",
      "INFO:tensorflow:loss = 309.33096, step = 1501 (0.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.2566\n",
      "INFO:tensorflow:loss = 263.3428, step = 1601 (1.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.966\n",
      "INFO:tensorflow:loss = 121.211975, step = 1701 (0.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.3651\n",
      "INFO:tensorflow:loss = 200.20404, step = 1801 (1.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0148\n",
      "INFO:tensorflow:loss = 140.30722, step = 1901 (1.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.401\n",
      "INFO:tensorflow:loss = 259.25394, step = 2001 (0.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.0138\n",
      "INFO:tensorflow:loss = 164.36613, step = 2101 (1.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.311\n",
      "INFO:tensorflow:loss = 219.4206, step = 2201 (0.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.282\n",
      "INFO:tensorflow:loss = 105.044586, step = 2301 (1.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.8445\n",
      "INFO:tensorflow:loss = 135.74626, step = 2401 (1.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.54\n",
      "INFO:tensorflow:loss = 153.25328, step = 2501 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.5476\n",
      "INFO:tensorflow:loss = 163.42114, step = 2601 (1.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.342\n",
      "INFO:tensorflow:loss = 126.095, step = 2701 (0.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.4128\n",
      "INFO:tensorflow:loss = 105.249825, step = 2801 (1.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.5031\n",
      "INFO:tensorflow:loss = 89.77777, step = 2901 (1.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.614\n",
      "INFO:tensorflow:loss = 111.481346, step = 3001 (0.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.6427\n",
      "INFO:tensorflow:loss = 72.62408, step = 3101 (1.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.592\n",
      "INFO:tensorflow:loss = 105.40516, step = 3201 (0.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.7472\n",
      "INFO:tensorflow:loss = 110.049164, step = 3301 (1.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.765\n",
      "INFO:tensorflow:loss = 75.72208, step = 3401 (0.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.1873\n",
      "INFO:tensorflow:loss = 80.141365, step = 3501 (1.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.2278\n",
      "INFO:tensorflow:loss = 38.002243, step = 3601 (1.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.85\n",
      "INFO:tensorflow:loss = 84.45732, step = 3701 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.1205\n",
      "INFO:tensorflow:loss = 56.81179, step = 3801 (1.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.717\n",
      "INFO:tensorflow:loss = 121.76885, step = 3901 (0.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2015\n",
      "INFO:tensorflow:loss = 46.215717, step = 4001 (1.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.954\n",
      "INFO:tensorflow:loss = 77.33519, step = 4101 (1.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.399\n",
      "INFO:tensorflow:loss = 72.36723, step = 4201 (0.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.5393\n",
      "INFO:tensorflow:loss = 48.55276, step = 4301 (1.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.113\n",
      "INFO:tensorflow:loss = 35.113148, step = 4401 (0.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6172\n",
      "INFO:tensorflow:loss = 40.075855, step = 4501 (1.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.5052\n",
      "INFO:tensorflow:loss = 36.404438, step = 4601 (1.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.604\n",
      "INFO:tensorflow:loss = 67.130646, step = 4701 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.057\n",
      "INFO:tensorflow:loss = 29.308594, step = 4801 (1.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.1\n",
      "INFO:tensorflow:loss = 70.17121, step = 4901 (0.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9024\n",
      "INFO:tensorflow:loss = 50.14722, step = 5001 (1.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.383\n",
      "INFO:tensorflow:loss = 24.89878, step = 5101 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.6892\n",
      "INFO:tensorflow:loss = 33.293434, step = 5201 (1.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9923\n",
      "INFO:tensorflow:loss = 26.610651, step = 5301 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.157\n",
      "INFO:tensorflow:loss = 27.28745, step = 5401 (0.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9985\n",
      "INFO:tensorflow:loss = 23.38848, step = 5501 (1.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.134\n",
      "INFO:tensorflow:loss = 22.924635, step = 5601 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.5514\n",
      "INFO:tensorflow:loss = 44.48925, step = 5701 (1.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9985\n",
      "INFO:tensorflow:loss = 19.85147, step = 5801 (1.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.252\n",
      "INFO:tensorflow:loss = 36.069088, step = 5901 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.4244\n",
      "INFO:tensorflow:loss = 13.241636, step = 6001 (1.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.418\n",
      "INFO:tensorflow:loss = 22.570168, step = 6101 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2523\n",
      "INFO:tensorflow:loss = 34.440845, step = 6201 (1.294 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6300 into estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11.485264.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-10-18:17:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from estimator/model.ckpt-6300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-10-18:17:47\n",
      "INFO:tensorflow:Saving dict for global step 6300: global_step = 6300, loss = 6538.4795, mean_auc = 0.6986957\n",
      "{'loss': 6538.4795, 'global_step': 6300, 'mean_auc': 0.6986957}\n"
     ]
    }
   ],
   "source": [
    "estimator.train(input_fn=lambda: input_fn(train_dataset, NB_EPOCH))\n",
    "print(estimator.evaluate(input_fn=lambda: input_fn(test_dataset, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of code for something DeepChem can do in three lines.  The Tensorflow API is verbose and somewhat confusing.  It has seemingly arbitrary limitations, like assuming a model will only ever have one output, and therefore only allowing one label.  But for better or worse, it's a standard.\n",
    "\n",
    "Of course, if you just want to use a DeepChem model with a DeepChem dataset, there is no need for any of this.  Just use the DeepChem API.  But perhaps you want to use a DeepChem dataset with a model that has been implemented as an estimator.  In that case, `Dataset.make_iterator()` allows you to easily do that.  Or perhaps you have higher level workflow code that is written to work with estimators.  In that case, `make_estimator()` allows DeepChem models to easily fit into that workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
