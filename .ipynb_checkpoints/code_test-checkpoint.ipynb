{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'deepchem.splits.splitters' from '/home/ab/deepchem/deepchem/splits/splitters.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.splits.splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module deepchem.splits.splitters in deepchem.splits:\n",
      "\n",
      "NAME\n",
      "    deepchem.splits.splitters - Contains an abstract base class that supports chemically aware data splits.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Splitter\n",
      "            ButinaSplitter\n",
      "            FingerprintSplitter\n",
      "            IndexSplitter\n",
      "            IndiceSplitter\n",
      "            MaxMinSplitter\n",
      "            MolecularWeightSplitter\n",
      "            RandomGroupSplitter\n",
      "            RandomSplitter\n",
      "            RandomStratifiedSplitter\n",
      "            ScaffoldSplitter\n",
      "            SingletaskStratifiedSplitter\n",
      "            SpecifiedSplitter\n",
      "            TimeSplitterPDBbind\n",
      "    \n",
      "    class ButinaSplitter(Splitter)\n",
      "     |  Class for doing data splits based on the butina clustering of a bulk tanimoto\n",
      "     |  fingerprint matrix.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ButinaSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  split(self, dataset, frac_train=None, frac_valid=None, frac_test=None, log_every_n=1000, cutoff=0.18)\n",
      "     |      Splits internal compounds into train and validation based on the butina\n",
      "     |      clustering algorithm. This splitting algorithm has an O(N^2) run time, where N\n",
      "     |      is the number of elements in the dataset. The dataset is expected to be a classification\n",
      "     |      dataset.\n",
      "     |      \n",
      "     |      This algorithm is designed to generate validation data that are novel chemotypes.\n",
      "     |      \n",
      "     |      Note that this function entirely disregards the ratios for frac_train, frac_valid,\n",
      "     |      and frac_test. Furthermore, it does not generate a test set, only a train and valid set.\n",
      "     |      \n",
      "     |      Setting a small cutoff value will generate smaller, finer clusters of high similarity,\n",
      "     |      whereas setting a large cutoff value will generate larger, coarser clusters of low similarity.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class FingerprintSplitter(Splitter)\n",
      "     |  Class for doing data splits based on the fingerprints of small molecules\n",
      "     |  O(N**2) algorithm\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FingerprintSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  split(self, dataset, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=1000)\n",
      "     |      Splits internal compounds into train/validation/test by fingerprint.\n",
      "     |  \n",
      "     |  update_distances(self, last_selected, cur_distances, distance_matrix, dont_update)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class IndexSplitter(Splitter)\n",
      "     |  Class for simple order based splits.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndexSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      "     |      Splits internal compounds into train/validation/test in provided order.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class IndiceSplitter(Splitter)\n",
      "     |  Class for splits based on input order.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndiceSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False, valid_indices=None, test_indices=None)\n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      valid_indices: list of int\n",
      "     |          indices of samples in the valid set\n",
      "     |      test_indices: list of int\n",
      "     |          indices of samples in the test set\n",
      "     |  \n",
      "     |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      "     |      Splits internal compounds into train/validation/test in designated order.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MaxMinSplitter(Splitter)\n",
      "     |  Class for doing splits based on the MaxMin diversity algorithm. Intuitively,\n",
      "     |  the test set is comprised of the most diverse compounds of the entire dataset.\n",
      "     |  Furthermore, the validation set is comprised of diverse compounds under\n",
      "     |  the test set.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MaxMinSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      "     |      Splits internal compounds randomly into train/validation/test.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MolecularWeightSplitter(Splitter)\n",
      "     |  Class for doing data splits by molecular weight.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MolecularWeightSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      "     |      Splits internal compounds into train/validation/test using the MW calculated\n",
      "     |      by SMILES string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RandomGroupSplitter(Splitter)\n",
      "     |  Abstract base class for chemically aware splits..\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomGroupSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, groups, *args, **kwargs)\n",
      "     |      A splitter class that splits on groupings. An example use case is when there\n",
      "     |      are multiple conformations of the same molecule that share the same topology.\n",
      "     |      This splitter subsequently guarantees that resulting splits preserve groupings.\n",
      "     |      \n",
      "     |      Note that it doesn't do any dynamic programming or something fancy to try to\n",
      "     |      maximize the choice such that frac_train, frac_valid, or frac_test is maximized.\n",
      "     |      It simply permutes the groups themselves. As such, use with caution if the number\n",
      "     |      of elements per group varies significantly.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      groups: array like list of hashables\n",
      "     |        An auxiliary array indicating the group of each item.\n",
      "     |      \n",
      "     |      Eg:\n",
      "     |      g: 3 2 2 0 1 1 2 4 3\n",
      "     |      X: 0 1 2 3 4 5 6 7 8\n",
      "     |      \n",
      "     |      Eg:\n",
      "     |      g: a b b e q x a a r\n",
      "     |      X: 0 1 2 3 4 5 6 7 8\n",
      "     |  \n",
      "     |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      "     |      Stub to be filled in by child classes.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RandomSplitter(Splitter)\n",
      "     |  Class for doing random data splits.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      "     |      Splits internal compounds randomly into train/validation/test.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RandomStratifiedSplitter(Splitter)\n",
      "     |  RandomStratified Splitter class.\n",
      "     |  \n",
      "     |  For sparse multitask datasets, a standard split offers no guarantees that the\n",
      "     |  splits will have any activate compounds. This class guarantees that each task\n",
      "     |  will have a proportional split of the activates in a split. TO do this, a\n",
      "     |  ragged split is performed with different numbers of compounds taken from each\n",
      "     |  task. Thus, the length of the split arrays may exceed the split of the\n",
      "     |  original array. That said, no datapoint is copied to more than one split, so\n",
      "     |  correctness is still ensured.\n",
      "     |  \n",
      "     |  Note that this splitter is only valid for boolean label data.\n",
      "     |  \n",
      "     |  TODO(rbharath): This splitter should be refactored to match style of other\n",
      "     |  splitter classes.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomStratifiedSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  get_task_split_indices(self, y, w, frac_split)\n",
      "     |      Returns num datapoints needed per task to split properly.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Needs custom implementation due to ragged splits for stratification.\n",
      "     |  \n",
      "     |  split(self, dataset, frac_split, split_dirs=None)\n",
      "     |      Method that does bulk of splitting dataset.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000)\n",
      "     |      Custom split due to raggedness in original split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ScaffoldSplitter(Splitter)\n",
      "     |  Class for doing data splits based on the scaffold of small molecules.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ScaffoldSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  split(self, dataset, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=1000)\n",
      "     |      Splits internal compounds into train/validation/test by scaffold.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SingletaskStratifiedSplitter(Splitter)\n",
      "     |  Class for doing data splits by stratification on a single task.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  >>> n_samples = 100\n",
      "     |  >>> n_features = 10\n",
      "     |  >>> n_tasks = 10\n",
      "     |  >>> X = np.random.rand(n_samples, n_features)\n",
      "     |  >>> y = np.random.rand(n_samples, n_tasks)\n",
      "     |  >>> w = np.ones_like(y)\n",
      "     |  >>> dataset = DiskDataset.from_numpy(np.ones((100,n_tasks)), np.ones((100,n_tasks)), verbose=False)\n",
      "     |  >>> splitter = SingletaskStratifiedSplitter(task_number=5, verbose=False)\n",
      "     |  >>> train_dataset, test_dataset = splitter.train_test_split(dataset)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SingletaskStratifiedSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, task_number=0, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      task_number: int (Optional, Default 0)\n",
      "     |        Task number for stratification.\n",
      "     |      verbose: bool (Optional, Default False)\n",
      "     |        Controls logging frequency.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, seed=None, log_every_n=None, **kwargs)\n",
      "     |      Splits compounds into k-folds using stratified sampling.\n",
      "     |      Overriding base class k_fold_split.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: dc.data.Dataset object\n",
      "     |        Dataset.\n",
      "     |      k: int\n",
      "     |        Number of folds.\n",
      "     |      seed: int (Optional, Default None)\n",
      "     |        Random seed.\n",
      "     |      log_every_n: int (Optional, Default None)\n",
      "     |        Log every n examples (not currently used).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      fold_datasets: List\n",
      "     |        List containing dc.data.Dataset objects\n",
      "     |  \n",
      "     |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      "     |      Splits compounds into train/validation/test using stratified sampling.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: dc.data.Dataset object\n",
      "     |        Dataset.\n",
      "     |      seed: int (Optional, Default None)\n",
      "     |        Random seed.\n",
      "     |      frac_train: float (Optional, Default .8)\n",
      "     |        Fraction of dataset put into training data.\n",
      "     |      frac_valid: float (Optional, Default .1)\n",
      "     |        Fraction of dataset put into validation data.\n",
      "     |      frac_test: float (Optional, Default .1)\n",
      "     |        Fraction of dataset put into test data.\n",
      "     |      log_every_n: int (Optional, Default None)\n",
      "     |        Log every n examples (not currently used).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      retval: Tuple\n",
      "     |        Tuple containing train indices, valid indices, and test indices\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SpecifiedSplitter(Splitter)\n",
      "     |  Class that splits data according to user specification.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SpecifiedSplitter\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, input_file, split_field, verbose=False)\n",
      "     |      Provide input information for splits.\n",
      "     |  \n",
      "     |  split(self, dataset, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=1000)\n",
      "     |      Splits internal compounds into train/validation/test by user-specification.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Splitter(builtins.object)\n",
      "     |  Abstract base class for chemically aware splits..\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  split(self, dataset, frac_train=None, frac_valid=None, frac_test=None, log_every_n=None, verbose=False)\n",
      "     |      Stub to be filled in by child classes.\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TimeSplitterPDBbind(Splitter)\n",
      "     |  Abstract base class for chemically aware splits..\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimeSplitterPDBbind\n",
      "     |      Splitter\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, ids, year_file=None, verbose=False)\n",
      "     |      Creates splitter object.\n",
      "     |  \n",
      "     |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      "     |      Splits protein-ligand pairs in PDBbind into train/validation/test in time order.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Splitter:\n",
      "     |  \n",
      "     |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dataset: Dataset\n",
      "     |      Dataset to do a k-fold split\n",
      "     |      \n",
      "     |      k: int\n",
      "     |      number of folds\n",
      "     |      \n",
      "     |      directories: list of str\n",
      "     |      list of length 2*k filepaths to save the result disk-datasets\n",
      "     |      \n",
      "     |      kwargs\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      list of length k tuples of (train, cv)\n",
      "     |  \n",
      "     |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      "     |      Splits self into train/test sets.\n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      "     |      Splits self into train/validation/test sets.\n",
      "     |      \n",
      "     |      Returns Dataset objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Splitter:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    ClusterFps(fps, cutoff=0.2)\n",
      "    \n",
      "    generate_scaffold(smiles, include_chirality=False)\n",
      "        Compute the Bemis-Murcko scaffold for a SMILES string.\n",
      "    \n",
      "    randomize_arrays(array_list)\n",
      "\n",
      "DATA\n",
      "    __copyright__ = 'Copyright 2016, Stanford University'\n",
      "    __license__ = 'MIT'\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    unicode_literals = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', ...\n",
      "\n",
      "AUTHOR\n",
      "    Bharath Ramsundar, Aneesh Pappu\n",
      "\n",
      "FILE\n",
      "    /home/ab/deepchem/deepchem/splits/splitters.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dc.splits.splitters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.splits.splitters import ScaffoldSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ScaffoldSplitter in module deepchem.splits.splitters:\n",
      "\n",
      "class ScaffoldSplitter(Splitter)\n",
      " |  Class for doing data splits based on the scaffold of small molecules.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ScaffoldSplitter\n",
      " |      Splitter\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  split(self, dataset, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=1000)\n",
      " |      Splits internal compounds into train/validation/test by scaffold.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Splitter:\n",
      " |  \n",
      " |  __init__(self, verbose=False)\n",
      " |      Creates splitter object.\n",
      " |  \n",
      " |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset: Dataset\n",
      " |      Dataset to do a k-fold split\n",
      " |      \n",
      " |      k: int\n",
      " |      number of folds\n",
      " |      \n",
      " |      directories: list of str\n",
      " |      list of length 2*k filepaths to save the result disk-datasets\n",
      " |      \n",
      " |      kwargs\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of length k tuples of (train, cv)\n",
      " |  \n",
      " |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      " |      Splits self into train/test sets.\n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      " |      Splits self into train/validation/test sets.\n",
      " |      \n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Splitter:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ScaffoldSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.splits.splitters import SpecifiedSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SpecifiedSplitter in module deepchem.splits.splitters:\n",
      "\n",
      "class SpecifiedSplitter(Splitter)\n",
      " |  Class that splits data according to user specification.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SpecifiedSplitter\n",
      " |      Splitter\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_file, split_field, verbose=False)\n",
      " |      Provide input information for splits.\n",
      " |  \n",
      " |  split(self, dataset, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=1000)\n",
      " |      Splits internal compounds into train/validation/test by user-specification.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Splitter:\n",
      " |  \n",
      " |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset: Dataset\n",
      " |      Dataset to do a k-fold split\n",
      " |      \n",
      " |      k: int\n",
      " |      number of folds\n",
      " |      \n",
      " |      directories: list of str\n",
      " |      list of length 2*k filepaths to save the result disk-datasets\n",
      " |      \n",
      " |      kwargs\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of length k tuples of (train, cv)\n",
      " |  \n",
      " |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      " |      Splits self into train/test sets.\n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      " |      Splits self into train/validation/test sets.\n",
      " |      \n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Splitter:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SpecifiedSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.splits.splitters import IndexSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class IndexSplitter in module deepchem.splits.splitters:\n",
      "\n",
      "class IndexSplitter(Splitter)\n",
      " |  Class for simple order based splits.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      IndexSplitter\n",
      " |      Splitter\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      " |      Splits internal compounds into train/validation/test in provided order.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Splitter:\n",
      " |  \n",
      " |  __init__(self, verbose=False)\n",
      " |      Creates splitter object.\n",
      " |  \n",
      " |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset: Dataset\n",
      " |      Dataset to do a k-fold split\n",
      " |      \n",
      " |      k: int\n",
      " |      number of folds\n",
      " |      \n",
      " |      directories: list of str\n",
      " |      list of length 2*k filepaths to save the result disk-datasets\n",
      " |      \n",
      " |      kwargs\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of length k tuples of (train, cv)\n",
      " |  \n",
      " |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      " |      Splits self into train/test sets.\n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      " |      Splits self into train/validation/test sets.\n",
      " |      \n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Splitter:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(IndexSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.splits.splitters import IndiceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class IndiceSplitter in module deepchem.splits.splitters:\n",
      "\n",
      "class IndiceSplitter(Splitter)\n",
      " |  Class for splits based on input order.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      IndiceSplitter\n",
      " |      Splitter\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, verbose=False, valid_indices=None, test_indices=None)\n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      valid_indices: list of int\n",
      " |          indices of samples in the valid set\n",
      " |      test_indices: list of int\n",
      " |          indices of samples in the test set\n",
      " |  \n",
      " |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      " |      Splits internal compounds into train/validation/test in designated order.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Splitter:\n",
      " |  \n",
      " |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset: Dataset\n",
      " |      Dataset to do a k-fold split\n",
      " |      \n",
      " |      k: int\n",
      " |      number of folds\n",
      " |      \n",
      " |      directories: list of str\n",
      " |      list of length 2*k filepaths to save the result disk-datasets\n",
      " |      \n",
      " |      kwargs\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of length k tuples of (train, cv)\n",
      " |  \n",
      " |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      " |      Splits self into train/test sets.\n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      " |      Splits self into train/validation/test sets.\n",
      " |      \n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Splitter:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(IndiceSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.splits.splitters import RandomGroupSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomGroupSplitter in module deepchem.splits.splitters:\n",
      "\n",
      "class RandomGroupSplitter(Splitter)\n",
      " |  Abstract base class for chemically aware splits..\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomGroupSplitter\n",
      " |      Splitter\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, groups, *args, **kwargs)\n",
      " |      A splitter class that splits on groupings. An example use case is when there\n",
      " |      are multiple conformations of the same molecule that share the same topology.\n",
      " |      This splitter subsequently guarantees that resulting splits preserve groupings.\n",
      " |      \n",
      " |      Note that it doesn't do any dynamic programming or something fancy to try to\n",
      " |      maximize the choice such that frac_train, frac_valid, or frac_test is maximized.\n",
      " |      It simply permutes the groups themselves. As such, use with caution if the number\n",
      " |      of elements per group varies significantly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      groups: array like list of hashables\n",
      " |        An auxiliary array indicating the group of each item.\n",
      " |      \n",
      " |      Eg:\n",
      " |      g: 3 2 2 0 1 1 2 4 3\n",
      " |      X: 0 1 2 3 4 5 6 7 8\n",
      " |      \n",
      " |      Eg:\n",
      " |      g: a b b e q x a a r\n",
      " |      X: 0 1 2 3 4 5 6 7 8\n",
      " |  \n",
      " |  split(self, dataset, seed=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, log_every_n=None)\n",
      " |      Stub to be filled in by child classes.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Splitter:\n",
      " |  \n",
      " |  k_fold_split(self, dataset, k, directories=None, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset: Dataset\n",
      " |      Dataset to do a k-fold split\n",
      " |      \n",
      " |      k: int\n",
      " |      number of folds\n",
      " |      \n",
      " |      directories: list of str\n",
      " |      list of length 2*k filepaths to save the result disk-datasets\n",
      " |      \n",
      " |      kwargs\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of length k tuples of (train, cv)\n",
      " |  \n",
      " |  train_test_split(self, dataset, train_dir=None, test_dir=None, seed=None, frac_train=0.8, verbose=True)\n",
      " |      Splits self into train/test sets.\n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  train_valid_test_split(self, dataset, train_dir=None, valid_dir=None, test_dir=None, frac_train=0.8, frac_valid=0.1, frac_test=0.1, seed=None, log_every_n=1000, verbose=True)\n",
      " |      Splits self into train/validation/test sets.\n",
      " |      \n",
      " |      Returns Dataset objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Splitter:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomGroupSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.utils.save import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import unittest\n",
    "import tempfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splittype=\"scaffold\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_transforms=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_transforms=[\"normalize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_params={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tasks=[\"log-solubility\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_type=\"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"/home/ab/deepchem/deepchem/models/tests/example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound ID</th>\n",
       "      <th>log-solubility</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amigdalin</td>\n",
       "      <td>0.974</td>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fenfuram</td>\n",
       "      <td>2.885</td>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citral</td>\n",
       "      <td>2.579</td>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Picene</td>\n",
       "      <td>6.618</td>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thiophene</td>\n",
       "      <td>2.232</td>\n",
       "      <td>c1ccsc1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Compound ID  log-solubility  \\\n",
       "0   Amigdalin           0.974   \n",
       "1    Fenfuram           2.885   \n",
       "2      citral           2.579   \n",
       "3      Picene           6.618   \n",
       "4   Thiophene           2.232   \n",
       "\n",
       "                                              smiles  \n",
       "0  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...  \n",
       "1                             Cc1occc1C(=O)Nc2ccccc2  \n",
       "2                               CC(C)=CCCC(C)=CC(=O)  \n",
       "3                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43  \n",
       "4                                            c1ccsc1  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=os.path.join(\"/home/ab/deepchem/deepchem/models/tests/example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurizer=dc.feat.CircularFingerprint(size=1024)\n",
    "loader = dc.data.CSVLoader(tasks=tasks, smiles_field=\"smiles\",featurizer=featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from /home/ab/deepchem/deepchem/models/tests/example.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "TIMING: featurizing shard 0 took 0.031 s\n",
      "TIMING: dataset construction took 0.042 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "dataset1=loader.featurize(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = ScaffoldSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sf=ScaffoldSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9, 8, 7, 6, 5, 4, 3], [], [2, 1, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.split(dataset1,frac_train=0.7,frac_valid=0.1,frac_test=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset,valid_dataset,test_dataset=sf.split(dataset1,frac_train=0.6,frac_valid=0.2,frac_test=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter=IndexSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(range(0, 7), range(7, 9), range(9, 10))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.split(dataset1,frac_test=0.1,frac_train=0.7,frac_valid=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data,train_data,valid_data=splitter.split(dataset1,frac_test=0.1,frac_train=0.7,frac_valid=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 7)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 7)\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter=IndiceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [], [])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.split(dataset1,frac_train=0.8,frac_valid=0.1,frac_test=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smiles=data['log-solubility'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0.974 2.885 2.579 6.618 2.232 2.733 6.545 4.138 4.533 5.246] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-c744e038978c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpecifiedSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/deepchem/deepchem/splits/splitters.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_file, split_field, verbose)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;34m\"\"\"Provide input information for splits.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0mraw_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_field\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepchem/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepchem/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepchem/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1269\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[0.974 2.885 2.579 6.618 2.232 2.733 6.545 4.138 4.533 5.246] not in index'"
     ]
    }
   ],
   "source": [
    "splitter = SpecifiedSplitter(input_data,smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
